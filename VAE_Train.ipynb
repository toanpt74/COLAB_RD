{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/VAE_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import numpy as np\n",
        "# set a random seed\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        "# parameters for building the model and training\n",
        "\n",
        "\"\"\"\n",
        "Defining Functions\n",
        "\"\"\"\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "LATENT_DIM = 128\n",
        "COL = 496 #width\n",
        "ROW = 64 #height\n",
        "def get_dataset(image_dir):\n",
        "    image_file_list = os.listdir(image_dir)\n",
        "    image_paths = [os.path.join(image_dir, fname) for fname in image_file_list]\n",
        "    random.shuffle(image_paths)\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((image_paths))\n",
        "    print(train_data)\n",
        "    print(\"Training dataset: {} images\".format(len(image_paths)))\n",
        "    return train_data, len(image_paths)\n",
        "#\n",
        "def pre_image(image_filename):\n",
        "    img_raw = tf.io.read_file(image_filename)\n",
        "    image = tf.image.decode_bmp(img_raw)\n",
        "\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    image = tf.image.resize(image, (ROW, COL))\n",
        "    image = image / 255.0\n",
        "    image = tf.reshape(image, shape=(COL, ROW, 1,))\n",
        "    print(image.shape)\n",
        "    return image\n",
        "\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mu, sigma = inputs\n",
        "        batch = tf.shape(mu)[0]\n",
        "        dim = tf.shape(mu)[1]\n",
        "        epsilon = keras.backend.random_normal(shape=(batch, dim))\n",
        "        z = mu + tf.exp(0.5 * sigma) * epsilon\n",
        "        #z = mu + tf.exp(0.5 * sigma\n",
        "        return z\n",
        "\n",
        "\n",
        "def encoder_layers(inputs, latent_dim):\n",
        "    x = layers.Conv2D(filters=4, kernel_size=3, strides=2, padding=\"same\", activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    #x = layers.Conv2D(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    batch_3 = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Flatten()(batch_3)\n",
        "\n",
        "    mu = layers.Dense(latent_dim, name='latent_mu')(x)\n",
        "    sigma = layers.Dense(latent_dim, name='latent_sigma')(x)\n",
        "    return mu, sigma, batch_3.shape\n",
        "\n",
        "\n",
        "def encoder_model(latent_dim, input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=latent_dim)\n",
        "    z = Sampling()((mu, sigma))\n",
        "    model = keras.Model(inputs, outputs=[mu, sigma, z], name='Encoder')\n",
        "    model.summary()\n",
        "    keras.utils.plot_model(\n",
        "        model,\n",
        "        to_file='encoder.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True\n",
        "    )\n",
        "    return model, conv_shape\n",
        "\n",
        "\n",
        "def decoder_layers(inputs, conv_shape):\n",
        "    units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "    x = layers.Dense(units, activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    #x = layers.Conv2DTranspose(filters=8, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=4, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def decoder_model(latent_dim, conv_shape):\n",
        "    inputs = layers.Input(shape=(latent_dim,))\n",
        "    outputs = decoder_layers(inputs, conv_shape)\n",
        "    model = keras.Model(inputs, outputs, name='Decoder')\n",
        "    model.summary()\n",
        "    keras.utils.plot_model(\n",
        "        model,\n",
        "        to_file='decoder.png',\n",
        "        show_shapes=True,\n",
        "        show_layer_names=True\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
        "    kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "    return tf.reduce_mean(kl_loss) * -0.5\n",
        "\n",
        "\n",
        "def vae_model(encoder, decoder, input_shape):\n",
        "    inputs = keras.layers.Input(shape=input_shape)\n",
        "    mu, sigma, z = encoder(inputs)\n",
        "    reconstructed = decoder(z)\n",
        "    model = keras.Model(inputs=inputs, outputs=reconstructed)\n",
        "    loss = kl_reconstruction_loss(inputs, z, mu, sigma)\n",
        "    model.add_loss(loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_models(input_shape, latent_dim):\n",
        "    encoder, conv_shape = encoder_model(latent_dim=latent_dim, input_shape=input_shape)\n",
        "    decoder = decoder_model(latent_dim=latent_dim, conv_shape=conv_shape)\n",
        "    vae = vae_model(encoder, decoder, input_shape=input_shape)\n",
        "    return encoder, decoder, vae\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, step, test_input):\n",
        "    predictions = model.predict(test_input)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        img = predictions[i, :, :, 0] * 255\n",
        "        img = img.astype('int32')\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    fig.suptitle(\"epoch: {}, step: {}\".format(epoch, step))\n",
        "    plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))\n",
        "    fig.clear()\n",
        "    plt.close(fig)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "VAE model\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def Train_VAE(datapath = \"\", epochs=2000,use_transferlearning = False,model_path = \"\"):\n",
        "    # initial_learning_rate = 0.01\n",
        "    # lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    #     initial_learning_rate,\n",
        "    #     decay_steps=5000,\n",
        "    #     decay_rate=0.96,\n",
        "    #     staircase=True)\n",
        "\n",
        "    if use_transferlearning:\n",
        "        vae = tf.keras.models.load_model(model_path)\n",
        "    else:\n",
        "        encoder, decoder, vae = get_models(input_shape=(COL, ROW, 1,), latent_dim=LATENT_DIM)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "    loss_metric = keras.metrics.Mean()\n",
        "    mse_loss = keras.losses.MeanSquaredError()\n",
        "\n",
        "    '''\n",
        "    Preparing dataset\n",
        "    '''\n",
        "    train_data, no_train = get_dataset(datapath)\n",
        "    train_ds = (train_data\n",
        "                .shuffle(no_train)\n",
        "                .map(pre_image, num_parallel_calls=AUTO)\n",
        "                .batch(BATCH_SIZE)\n",
        "                .prefetch(buffer_size=AUTO))\n",
        "\n",
        "    '''\n",
        "    Training loop\n",
        "    '''\n",
        "    os.system(\"nvidia-smi\")\n",
        "\n",
        "    # random_vector_for_generation = tf.random.normal(shape=[16, LATENT_DIM])\n",
        "    # generate_and_save_images(decoder, 0, 0, random_vector_for_generation)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Start of epoch %d' % (epoch,))\n",
        "        for step, x_batch_train in enumerate(train_ds):\n",
        "            with tf.GradientTape() as tape:\n",
        "                reconstructed = vae(x_batch_train)\n",
        "                flattened_inputs = tf.reshape(x_batch_train, shape=[-1])\n",
        "                flattened_outputs = tf.reshape(reconstructed, shape=[-1])\n",
        "                loss = mse_loss(flattened_inputs, flattened_outputs) * COL * ROW\n",
        "                loss += sum(vae.losses)\n",
        "\n",
        "            grads = tape.gradient(loss, vae.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "            loss_metric(loss)\n",
        "            print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result().numpy()))\n",
        "        if epoch % 5 == 0:\n",
        "            vae.save(f'model_vae\\\\model_{epoch}__{loss}', save_format=\"tf\")\n",
        "\n",
        "\n",
        "dir = r'E:\\ToanPT\\1.Code_train_Unet\\data\\train'\n",
        "\n",
        "Train_VAE(datapath=dir,epochs=20001,use_transferlearning = False,\n",
        "          model_path=r\"E:\\ToanPT\\1.Code_train_Unet\\models\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"DONE\")\n"
      ],
      "metadata": {
        "id": "JKHwOvJxl0Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4RckuC1l0b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3L8d3zMl0fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rn97yjzLl0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Vp7SXWgl0l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yyNm0RXWl0o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcRyqd1Zl0sc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}