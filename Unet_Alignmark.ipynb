{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/Unet_Alignmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEukNkjRvcMO",
        "outputId": "fc6ce3b1-c2cc-4e33-dcb8-307c757e5ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from labelme import utils\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "import os\n",
        "import os.path\n",
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import PIL\n",
        "import datetime\n",
        "from keras import backend as K\n",
        "from pathlib import Path\n",
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import BatchNormalization, Input, \\\n",
        "    Activation, Conv2D, MaxPooling2D, Conv2DTranspose, Add, concatenate, Concatenate, UpSampling2D, Dropout\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Config CPU,GPU\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "input_shape =(512,384,1) #(960, 1280, 1)\n",
        "train_region = (130, 1170, 384, 384) #(x, y), with, height\n",
        "OPTIMIZER = tf.keras.optimizers.Adam()\n",
        "epochs=10000\n",
        "BATCH_SIZE=2\n",
        "\n",
        "def LoadDataToTrain(input_shape=(256,256,1), path='', test_ratio=0.2, Use_Region = False):\n",
        "    images_path = path\n",
        "    X_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'train')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    Y_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'label')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "\n",
        "    train_img_paths, test_img_paths, train_label_paths, test_label_paths = train_test_split(X_path, Y_path,test_size=0.2)\n",
        "    if Use_Region == True:\n",
        "        X_train = loadImageCrop(train_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_train = loadImageCrop(train_label_paths, input_shape=input_shape, islabel=1)\n",
        "        X_test = loadImageCrop(test_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_test = loadImageCrop(test_label_paths, input_shape=input_shape, islabel=1)\n",
        "    else:\n",
        "        X_train = loadImages(train_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_train = loadImages(train_label_paths, input_shape=input_shape, islabel=1)\n",
        "        X_test = loadImages(test_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_test = loadImages(test_label_paths, input_shape=input_shape, islabel=1)\n",
        "    Y_train = np.where(Y_train < 1, 0.0, 1.0)\n",
        "    Y_test = np.where(Y_test < 1, 0.0, 1.0)\n",
        "\n",
        "    X_test = X_test.reshape((X_test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    X_train = X_train.reshape((X_train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "def LoadDataTrain(input_shape=(256,256,1), path='', test_ratio=0.2):\n",
        "    X_Train = None\n",
        "    Y_Train = None\n",
        "    X_Test = None\n",
        "    Y_Test = None\n",
        "\n",
        "    #(X_Train, Y_Train), (X_Test, Y_Test) = LoadDataFromImage(input_shape=input_shape,path=path, test_ratio=test_ratio)\n",
        "    path_train = r\"E:\\ToanPT\\Data_train\\train\"\n",
        "    path_test = r\"E:\\ToanPT\\Data_train\\test\"\n",
        "    (X_Train, Y_Train) = LoadDataFromImage(input_shape=input_shape, path=path_train, test_ratio=test_ratio)\n",
        "    (X_Test, Y_Test) = LoadDataFromImage(input_shape=input_shape, path=path_test, test_ratio=test_ratio)\n",
        "\n",
        "    X_Test = X_Test.reshape((X_Test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_Test = Y_Test.reshape((Y_Test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    X_Train = X_Train.reshape((X_Train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_Train = Y_Train.reshape((Y_Train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    return (X_Train, Y_Train), (X_Test, Y_Test)\n",
        "\n",
        "def LoadDataFromImage(input_shape=(256,256,1), path='', test_ratio=0.2):\n",
        "    images_path = path\n",
        "\n",
        "    X_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'train')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    Y_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'label')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    #Xu dung crop vung anh\n",
        "    #X = loadImageCrop(X_path, train_region=train_region, input_shape=input_shape, islabel=0)\n",
        "    #Y = loadImageCrop(Y_path, train_region=train_region, input_shape=input_shape, islabel=1)\n",
        "\n",
        "    X = loadImages(X_path, input_shape=input_shape, islabel=0)\n",
        "    Y = loadImages(Y_path, input_shape=input_shape, islabel=1)\n",
        "\n",
        "    Y = np.where(Y < 0.5, 0.0, 1.0)\n",
        "    \"\"\"\n",
        "    (n, _, _) = X.shape\n",
        "    permutate = np.random.permutation(n)\n",
        "    X = X[permutate, :, :]\n",
        "    Y = Y[permutate, :, :]\n",
        "    n_test = int(n * test_ratio)\n",
        "    X_test = X[0:n_test, :, :]\n",
        "    Y_test = Y[0:n_test, :, :]\n",
        "    X_train = X[n_test:n, :, :]\n",
        "    Y_train = Y[n_test:n, :, :]\n",
        "    \"\"\"\n",
        "    return (X,Y)  #(X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "def loadImages(images_path, input_shape, islabel=0):\n",
        "    data = []\n",
        "    print(\"**************\")\n",
        "    for file in images_path:\n",
        "        print(\"Load file:\" + file)\n",
        "        im = cv2.imread(file)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        im = cv2.resize(im, (input_shape[1], input_shape[0]))\n",
        "        im = np.array(im)\n",
        "        im = im.astype('float32')\n",
        "        temp = im / 255.0\n",
        "        if islabel ==1 :\n",
        "            print(temp.shape)\n",
        "            print(np.sum(temp))\n",
        "        data.append(temp)\n",
        "    X = np.array(data)\n",
        "    return X\n",
        "\n",
        "def loadImageCrop(images_path, train_region, input_shape, islabel=0):\n",
        "    data = []\n",
        "\n",
        "    for file in images_path:\n",
        "        print(\"Load file:\" + file)\n",
        "        im = cv2.imread(file)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        crop_img = im[train_region[1]:train_region[1] + train_region[3],\n",
        "                   train_region[0]:train_region[0] + train_region[2]]\n",
        "\n",
        "        crop_img = cv2.resize(crop_img, (input_shape[1], input_shape[0]))\n",
        "\n",
        "        crop_img = np.array(crop_img)\n",
        "        crop_img = crop_img.astype('float32')\n",
        "        temp = crop_img / 255.0\n",
        "        if islabel ==1 and np.sum(temp) <500:\n",
        "            temp[:,:]=0.0\n",
        "\n",
        "        data.append(temp)\n",
        "    X = np.array(data)\n",
        "    return X\n",
        "\n",
        "def bn_Conv2d(x, filters=16, kernel_size=(3, 3), padding='same', strides=(1, 1), dilation_rate=(1, 1), name='Conv', activation='relu'):\n",
        "    y = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "               kernel_initializer='he_normal',\n",
        "               bias_initializer='he_normal',\n",
        "               #kernel_regularizer=kernel_regularizer,\n",
        "               #activity_regularizer=tf.keras.regularizers.L2(1e-5),\n",
        "               padding=padding,\n",
        "               use_bias=True,\n",
        "               strides=strides, dilation_rate=dilation_rate,)(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation(activation)(y)\n",
        "    return y\n",
        "def bn_Conv2DTranspose(x, filters=16, kernel_size=(3, 3), strides=(2, 2), padding='same', dilation_rate=(1, 1),\n",
        "                       name='transpose', activation='relu'):\n",
        "    up1 = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                          dilation_rate=dilation_rate, name=name)(x)\n",
        "    up1 = BatchNormalization()(up1)\n",
        "    up1 = Activation(activation)(up1)\n",
        "    return up1\n",
        "\n",
        "def AT_UNET_Seq(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_block= inputs\n",
        "    p=[]\n",
        "    for i in range(6):\n",
        "        en1 = bn_Conv2d(x=input_block, filters=2**i, kernel_size=(3,3), name='Enc_{0}_1'.format(i+1), dilation_rate=(1,1))\n",
        "        en2 = bn_Conv2d(x=en1, filters=2 ** (i+2), kernel_size=(3,3), name='Enc_{0}_2'.format(i + 1), dilation_rate=(2,2))\n",
        "        p.append(MaxPooling2D(pool_size=(2,2))(en2))\n",
        "\n",
        "        input_block=p[i]\n",
        "    trans = bn_Conv2d(x=en2, filters=128, kernel_size=(3,3), strides=(2,2), dilation_rate=(1,1), name='transfer')\n",
        "    de = trans\n",
        "    for i in range(5):\n",
        "        de= bn_Conv2DTranspose(x=de, filters=2**(6-i), kernel_size=(3,3), name='Dec_{0}'.format(i+1))\n",
        "        de= Add()([de, p[4-i]])\n",
        "    outputs = bn_Conv2DTranspose(x=de, filters=1, kernel_size=(3,3), name='Dec_6', activation='sigmoid')\n",
        "    model = Model(inputs=[inputs], outputs=[outputs], name='AT_UNET')\n",
        "    return model\n",
        "\n",
        "def AT_UNET(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_block= inputs\n",
        "    p=[]\n",
        "    for i in range(6):\n",
        "        en = bn_Conv2d(x=input_block, filters=2**i, kernel_size=(3,3), name='Enc_{0}_1'.format(i+1), dilation_rate=(1,1))\n",
        "        en = bn_Conv2d(x=en, filters=2 ** (i+1), kernel_size=(3,3), name='Enc_{0}_2'.format(i + 1), dilation_rate=(2,2))\n",
        "        en = bn_Conv2d(x=en, filters=2 ** (i+2), kernel_size=(3,3), name='Enc_{0}_3'.format(i + 1), dilation_rate=(3,3))\n",
        "        p.append(MaxPooling2D(pool_size=(2,2))(en))\n",
        "        input_block=p[i]\n",
        "    trans = bn_Conv2d(x=en, filters=128, kernel_size=(3,3), strides=(2,2), dilation_rate=(1,1), name='transfer')\n",
        "    de = trans\n",
        "    for i in range(5):\n",
        "        de= bn_Conv2DTranspose(x=de, filters=2**(6-i), kernel_size=(3,3), name='Dec_{0}'.format(i+1))\n",
        "        de= Add()([de, p[4-i]])\n",
        "    outputs = bn_Conv2DTranspose(x=de, filters=1, kernel_size=(3,3), name='Dec_6', activation='sigmoid')\n",
        "    model = Model(inputs=[inputs], outputs=[outputs], name='AT_UNET')\n",
        "    return model\n",
        "\n",
        "def New_AT_UNET(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_block= inputs\n",
        "    p=[]\n",
        "    for i in range(6):\n",
        "        en1 = bn_Conv2d(x=input_block, filters=2**i,\n",
        "                        kernel_size=(3,3), name='Enc_{0}_1'.format(i+1), dilation_rate=(1,1))\n",
        "        en2 = bn_Conv2d(x=input_block, filters=2 ** (i+1),\n",
        "                        kernel_size=(3,3), name='Enc_{0}_2'.format(i + 1), dilation_rate=(2,2))\n",
        "        en3 = bn_Conv2d(x=input_block, filters=2 ** (i+2),\n",
        "                        kernel_size=(3,3), name='Enc_{0}_3'.format(i + 1), dilation_rate=(3,3))\n",
        "        en = concatenate(inputs=[en1, en2, en3],axis=-1)\n",
        "        en= bn_Conv2d(x=en, filters=2 ** (i+2),\n",
        "                      kernel_size=(1,1), dilation_rate=(1,1), name='Enc_add_{0}'.format(i+1))\n",
        "        p.append(MaxPooling2D(pool_size=(2,2))(en))\n",
        "\n",
        "        input_block=p[i]\n",
        "    trans = bn_Conv2d(x=en, filters=128, kernel_size=(3,3), strides=(2,2), dilation_rate=(1,1), name='transfer')\n",
        "    de = trans\n",
        "    for i in range(5):\n",
        "        de= bn_Conv2DTranspose(x=de, filters=2**(6-i), kernel_size=(3,3), name='Dec_{0}'.format(i+1))\n",
        "        de= Add()([de, p[4-i]])\n",
        "    outputs = bn_Conv2DTranspose(x=de, filters=1, kernel_size=(3,3), name='Dec_6', activation='sigmoid')\n",
        "    model = Model(inputs=[inputs], outputs=[outputs], name='AT_UNET')\n",
        "    return model\n",
        "\n",
        "\"\"\"Dinh nghia model U-NET GOC\"\"\"\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters,3, padding='same')(inputs)\n",
        "    x= BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(num_filters, 3, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return  x\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPooling2D((2,2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs,skip_features ,num_filters):\n",
        "    x= Conv2DTranspose(num_filters,(2,2), strides=2, padding='same')(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "def buid_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    \"\"\"Encoder\"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "    \"\"\"Bridge\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "    \"\"\"Decoder\"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "    \"\"\"output\"\"\"\n",
        "    outputs = Conv2D(1, (1,1), padding='same', activation='sigmoid')(d4)\n",
        "    model = Model(inputs, outputs, name=\"U-NET\")\n",
        "    return  model\n",
        "\n",
        "\n",
        "def unet(pretrained_weights=None, input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(drop5))\n",
        "    merge6 = concatenate([drop4, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input=inputs, output=conv10)\n",
        "\n",
        "    model.compile(optimizer=OPTIMIZER, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # model.summary()\n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Image loading: \")\n",
        "\n",
        "path= r'E:\\2.AssyV3_DBending\\data'\n",
        "model_save_path = r'E:\\ToanPT\\1.Code_train_Unet\\models'\n",
        "path_save = r'E:\\2.AssyV3_DBending\\test\\image_detect'\n",
        "\n",
        "def train():\n",
        "    (x_train, y_train), (x_test, y_test) = LoadDataToTrain(input_shape=input_shape,path=path, Use_Region=False)\n",
        "\n",
        "    model =AT_UNET(input_shape=input_shape) #AT_UNET(input_shape=input_shape)\n",
        "    model.compile(optimizer=OPTIMIZER, loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    class SaveModel(keras.callbacks.Callback):\n",
        "        def __init__(self, path=None):\n",
        "            self.Path = path\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            loss = float(logs[\"loss\"])\n",
        "            acc = float(logs[\"accuracy\"])\n",
        "            val_loss = float(logs[\"val_loss\"])\n",
        "            val_acc = float(logs[\"val_accuracy\"])\n",
        "            filename = \"Small_weights-epc {0} -loss {1:.4f} -acc {2:.3f} -val_loss {3:.4f} -val_acc {4:.3f}.h5\".format(\n",
        "                epoch, loss, acc, val_loss, val_acc)\n",
        "\n",
        "            savepath = os.path.join(self.Path, filename)\n",
        "            #if acc > 0.995 and val_acc > 0.995:\n",
        "            self.model.save_weights(filepath=savepath)\n",
        "\n",
        "    callbackmonitor = [\n",
        "            keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "            SaveModel(\"./models/\")\n",
        "       ]\n",
        "\n",
        "    callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "                      ModelCheckpoint(\n",
        "                          os.path.join(model_save_path,\n",
        "                                       'unet-AssyDBending-{epoch:03d}--{loss:.6f}-{accuracy:.6f}--{val_loss:.6f}-{val_accuracy:.6f}.h5'),\n",
        "                          monitor='val_accuracy', save_best_only=False,\n",
        "                          save_weights_only=False, period=10, mode='auto', verbose=0),\n",
        "                     ]\n",
        "\n",
        "    model.fit(x_train, y_train, validation_data=(x_test, y_test), verbose=1,\n",
        "                  epochs=epochs, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                  callbacks=callbacks)\n",
        "\n",
        "def buildImage(x, y, input_shape):\n",
        "    try:\n",
        "        x = np.reshape(x, input_shape)\n",
        "        y = np.reshape(y, input_shape)\n",
        "        x = x * 255\n",
        "        x = cv2.cvtColor(x, cv2.COLOR_GRAY2RGB)\n",
        "        y = y * 255\n",
        "        x = x.astype('uint8')\n",
        "        y = y.astype('uint8')\n",
        "        cv2.threshold(y, 200, 255, cv2.THRESH_BINARY, y)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        raw = y\n",
        "        # y = cv2.erode(y, kernel=kernel, iterations=3)\n",
        "\n",
        "        y = cv2.erode(y, kernel=kernel, iterations=1)\n",
        "        # y = cv2.dilate(y, kernel=kernel, iterations=1)\n",
        "        contours, _ = cv2.findContours(y, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        index = -1\n",
        "        i = -1\n",
        "        area = 0\n",
        "        contours_filtered = []\n",
        "        for cnt in contours:\n",
        "            i = i + 1\n",
        "            contour_area = cv2.contourArea(cnt)\n",
        "            if contour_area > area:\n",
        "                index = i\n",
        "                area = contour_area\n",
        "        x_top, y_top, w, h = cv2.boundingRect(contours[index])\n",
        "        x = cv2.rectangle(x, (x_top, y_top), (x_top + w, y_top + h), (0, 0, 255), 1)\n",
        "        return x, y, raw\n",
        "    except:\n",
        "        print(\" Buil Image Exception\")\n",
        "\n",
        "def Predict():\n",
        "\n",
        "    # image_path=r'E:\\1.AssyV3_Align\\DB1'\n",
        "    image_path=r'E:\\2.AssyV3_DBending\\test'\n",
        "    # model_file=r'E:\\ToanPT\\1.Code_train_Unet\\models\\unet-10000--0.000000-1.000000--0.013596-0.999356.h5'\n",
        "    model_file=r'E:\\ToanPT\\1.Code_train_Unet\\models\\unet-AssyDBending-540--0.009974-0.999938--0.017954-0.999532.h5'\n",
        "    model = load_model(model_file)  #models.load_model(model_file)\n",
        "\n",
        "    print(\"Load model complete\")\n",
        "\n",
        "    Img_path = [os.path.join(root, file) for root, _, files in\n",
        "                os.walk(os.path.join(image_path, 'train')) for file in files if\n",
        "                (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    for file_name in Img_path:\n",
        "        print(\"Load file:\" + file_name)\n",
        "        im = cv2.imread(file_name)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "        # Crop Image\n",
        "        \"\"\"\n",
        "        crop_img = im[train_region[1]:train_region[1] + train_region[3],\n",
        "                   train_region[0]:train_region[0] + train_region[2]]\n",
        "        crop_img = cv2.resize(crop_img, (input_shape[1], input_shape[0]))\n",
        "        crop_img = np.array(crop_img)\n",
        "        crop_img = crop_img.astype('float32')\n",
        "        crop_img = crop_img / 255.0\n",
        "        crop_img = crop_img.reshape((1, input_shape[0], input_shape[1]))\n",
        "        \"\"\"\n",
        "        X = cv2.resize(im,(input_shape[1], input_shape[0]))\n",
        "        X = np.array(X)\n",
        "        X= X.astype('float32')\n",
        "        X = X / 255.0\n",
        "        X = X.reshape((1, input_shape[0], input_shape[1]))\n",
        "\n",
        "        y = model.predict(X)\n",
        "\n",
        "        img, mask, raw_predict = buildImage(X, y, input_shape)\n",
        "        \"\"\"\n",
        "        y = np.reshape(y, input_shape)\n",
        "        y = y * 255\n",
        "        y = cv2.cvtColor(y, cv2.COLOR_GRAY2RGB)\n",
        "        y = y.astype('uint8')\n",
        "        \"\"\"\n",
        "\n",
        "        # plt.imshow(mask)\n",
        "        # plt.show()\n",
        "\n",
        "        directory = os.path.dirname(file_name)\n",
        "        path_save = os.path.join(directory, \"Image_Predict\")\n",
        "        print(path_save)\n",
        "        if not os.path.exists(path_save):\n",
        "            os.makedirs(path_save)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_draw.jpg\"), img)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_mask.jpg\"), mask)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_raw.jpg\"), raw_predict)\n",
        "\n",
        "    print('Predict Ok')\n",
        "\n",
        "def PredictRegion():\n",
        "\n",
        "    image_path = r'E:\\ToanPT\\Data_train\\test'\n",
        "    model_file = r'E:\\ToanPT\\1.Code_train_Unet\\2.2.0_071022AtcModel_COP_Resize_Left_DataArg=False_TrainRegion[200x60,1024x1536]-3000--0.000000-1.000000--0.000967-0.999933.h5'\n",
        "    model = load_model(model_file)  # models.load_model(model_file)\n",
        "    print(\"Load model complete\")\n",
        "\n",
        "    Img_path = [os.path.join(root, file) for root, _, files in\n",
        "                os.walk(os.path.join(image_path, 'train')) for file in files if\n",
        "                (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    for file_name in Img_path:\n",
        "        print(\"Load file:\" + file_name)\n",
        "        im = cv2.imread(file_name)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        crop_img = im[train_region[1]:train_region[1] + train_region[3],\n",
        "                   train_region[0]:train_region[0] + train_region[2]]\n",
        "        crop_img = cv2.resize(crop_img, (input_shape[1], input_shape[0]))\n",
        "        crop_img = np.array(crop_img)\n",
        "        crop_img = crop_img.astype('float32')\n",
        "        crop_img = crop_img / 255.0\n",
        "        crop_img = crop_img.reshape((1, input_shape[0], input_shape[1]))\n",
        "\n",
        "        X = np.array(crop_img)\n",
        "        y = model.predict(X)\n",
        "\n",
        "        img, mask, raw_predict = buildImage(X, y, input_shape)\n",
        "        directory = os.path.dirname(file_name)\n",
        "        path_save = os.path.join(directory, \"Image_Predict\")\n",
        "        print(path_save)\n",
        "        if not os.path.exists(path_save):\n",
        "            os.makedirs(path_save)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_draw.jpg\"), img)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_mask.jpg\"), mask)\n",
        "        cv2.imwrite(os.path.join(path_save, Path(file_name).stem + \"_img_predict_raw.jpg\"), raw_predict)\n",
        "    print('Predict Ok')\n",
        "\n",
        "\n",
        "# Predict()\n",
        "#train()\n",
        "\n",
        "model=AT_UNET_Seq((256,256,1))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "pqaJdfeiwFnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}