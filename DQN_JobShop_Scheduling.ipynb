{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/DQN_JobShop_Scheduling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import deque\n",
        "import keras\n",
        "from keras.layers import Dense, Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "\n",
        "class JobShop:\n",
        "    # This class is the environment of Job shop problem\n",
        "    bool_generate_random_jssp = None\n",
        "    number_job = None\n",
        "    number_machine = None\n",
        "    number_features = None\n",
        "    # the lower limit of one position of job 's processing time.\n",
        "    time_low = None\n",
        "    # the upper limit of one position of job 's processing time.\n",
        "    time_high = None\n",
        "    # Matrix of processing time, M_processing_time[i,j] is the processing time of job i 's position j.\n",
        "    M_processing_time = None\n",
        "    # Matrix of processing time, M_processing_order[i,j] is the machine restrain of job i 's position j.\n",
        "    M_processing_order = None\n",
        "    M_start_time = None\n",
        "    M_end_time = None\n",
        "    X_schedule_plan = None\n",
        "    schedule_line = None\n",
        "\n",
        "    def __init__(self, number_machine, number_job, time_low, time_high, bool_random):\n",
        "        self.number_job = number_job\n",
        "        self.bool_generate_random_jssp = random\n",
        "        self.number_machine = number_machine\n",
        "        self.time_low = time_low\n",
        "        self.time_high = time_high\n",
        "        self.schedule_line = []\n",
        "        self.GenerateRandomProblem()\n",
        "\n",
        "    def Get_Possible_Job_Position(self):\n",
        "        # ergodic the schedule_line, and return the possible position to produce of jobs\n",
        "\n",
        "        job_position_list = [0 for i in range(self.number_job)]\n",
        "        for job_id, job_position in self.schedule_line:\n",
        "            if job_position < self.number_machine-1:\n",
        "                job_position_list[job_id] = job_position+1\n",
        "            else:\n",
        "                job_position_list[job_id] = -1\n",
        "\n",
        "        return [[i, job_position_list[i]] for i in range(len(job_position_list))]\n",
        "\n",
        "    def Get_Features(self, possible_job_position):\n",
        "        # return the features of current state\n",
        "\n",
        "        featrues = []\n",
        "        for job_id, job_position in possible_job_position:\n",
        "            f_item = self.GetFeature(job_id, job_position)\n",
        "            featrues.append(f_item)\n",
        "\n",
        "        return featrues\n",
        "\n",
        "    def Step(self, action=None):\n",
        "        # be called in main function\n",
        "        # input action and return state score and done\n",
        "        # action: choose a job to process.\n",
        "        # state:\n",
        "        done = False\n",
        "        if action == None:\n",
        "            self.MeasurementAction(self.schedule_line)\n",
        "            possible_pob_position = self.Get_Possible_Job_Position()\n",
        "            state = np.array(self.Get_Features(possible_pob_position))\n",
        "            score = 0\n",
        "        else:\n",
        "            job_position_list = [0 for i in range(self.number_job)]\n",
        "            for job_id, job_position in self.schedule_line:\n",
        "                if job_position < self.number_machine-1:\n",
        "                    job_position_list[job_id] = job_position+1\n",
        "                else:\n",
        "                    job_position_list[job_id] = -1\n",
        "            if job_position_list[action] == -1:\n",
        "                done = True\n",
        "                canchoose = [[i, job_position_list[i]] for i in range(\n",
        "                    self.number_job) if job_position_list[i] != -1]\n",
        "                action = canchoose[0]\n",
        "            else:\n",
        "                action = [action, job_position_list[action]]\n",
        "\n",
        "            self.schedule_line.append(action)\n",
        "            self.MeasurementAction(self.schedule_line)\n",
        "            # self.PlotResult()\n",
        "            score = np.max(self.M_end_time)\n",
        "\n",
        "            possible_pob_position = self.Get_Possible_Job_Position()\n",
        "            state = np.array(self.Get_Features(possible_pob_position))\n",
        "#T\n",
        "        state = [np.reshape(state[i], (1, 2,)) for i in range(self.number_job)]\n",
        "\n",
        "        return state, score, done\n",
        "\n",
        "    def GenerateRandomProblem(self):\n",
        "        # Generate the jobshop problem\n",
        "        # random problem or a stable problem\n",
        "\n",
        "        if self.bool_generate_random_jssp == True:\n",
        "            a = list(range(self.time_low, self.time_high))\n",
        "            p = []\n",
        "            for k in range(self.number_job):\n",
        "                p.append(random.sample(a, self.number_machine))\n",
        "            self.M_processing_time = np.array(p)\n",
        "            a = list(range(self.number_machine))\n",
        "            r = []\n",
        "            for k in range(self.number_job):\n",
        "                r.append(random.sample(a, self.number_machine))\n",
        "            self.M_processing_order = np.array(r)\n",
        "            sum_time_of_job = np.sum(self.M_processing_time, axis=1)\n",
        "            for i in range(self.number_job):\n",
        "                for j in range(i+1, self.number_job):\n",
        "                    if sum_time_of_job[i] > sum_time_of_job[j]:\n",
        "                        a = np.copy(self.M_processing_time[j, :])\n",
        "                        self.M_processing_time[j,\n",
        "                                               :] = self.M_processing_time[i, :]\n",
        "                        self.M_processing_time[i, :] = a\n",
        "                        sum_time_of_job[i], sum_time_of_job[j] = sum_time_of_job[j], sum_time_of_job[i]\n",
        "\n",
        "            sum_time_of_mach = [[i, 0] for i in range(self.number_machine)]\n",
        "            for i in range(self.number_job):\n",
        "                for j in range(self.number_machine):\n",
        "                    sum_time_of_mach[self.M_processing_order[i, j]\n",
        "                                     ][1] += self.M_processing_time[i, j]\n",
        "\n",
        "            for i in range(self.number_machine):\n",
        "                for j in range(i+1, self.number_machine):\n",
        "                    if sum_time_of_mach[i][1] > sum_time_of_mach[j][1]:\n",
        "                        sum_time_of_mach[i], sum_time_of_mach[j] = sum_time_of_mach[j], sum_time_of_mach[i]\n",
        "\n",
        "            nr = np.zeros((self.number_job, self.number_machine), dtype=int)-1\n",
        "            for i in range(self.number_machine):\n",
        "                nr[self.M_processing_order == i] = sum_time_of_mach[i][0]\n",
        "\n",
        "            sum_time_of_mach = [[i, 0] for i in range(self.number_machine)]\n",
        "            for i in range(self.number_job):\n",
        "                for j in range(self.number_machine):\n",
        "                    sum_time_of_mach[self.M_processing_order[i, j]\n",
        "                                     ][1] += self.M_processing_time[i, j]\n",
        "            self.M_processing_order = nr\n",
        "        else:\n",
        "            self.M_processing_order = np.array(\n",
        "                [[1, 3, 0, 2], [0, 2, 1, 3], [3, 1, 2, 0], [1, 3, 0, 2], [0, 1, 2, 3]])\n",
        "            self.M_processing_time = np.array([[18, 20, 21, 17], [18, 26, 15, 16], [\n",
        "                17, 18, 27, 23], [18, 21, 25, 15], [22, 29, 28, 21]])\n",
        "\n",
        "    def MeasurementAction(self, action_history):\n",
        "        # measurement the action and return the makespan\n",
        "\n",
        "        M_start_time = np.zeros((self.number_machine, self.number_job))\n",
        "        M_end_time = np.zeros((self.number_machine, self.number_job))\n",
        "\n",
        "        timeline_machine = np.zeros((self.number_machine), dtype=int)\n",
        "        index_machine = np.zeros((self.number_machine), dtype=int)\n",
        "        timeline_job = np.zeros((self.number_job), dtype=int)\n",
        "        index_job = np.zeros((self.number_job), dtype=int)\n",
        "        X_schedule_plan = np.zeros(\n",
        "            (self.number_machine, self.number_job, 2), dtype=int)\n",
        "\n",
        "        for job_id, job_position in action_history:\n",
        "            machine_id = self.M_processing_order[job_id, job_position]\n",
        "            current_start_time = max(\n",
        "                timeline_machine[machine_id], timeline_job[job_id])\n",
        "            current_end_time = current_start_time + \\\n",
        "                self.M_processing_time[job_id, job_position]\n",
        "            timeline_machine[machine_id], timeline_job[job_id] = current_end_time, current_end_time\n",
        "            current_index = index_machine[machine_id]\n",
        "            M_start_time[machine_id, current_index] = current_start_time\n",
        "            M_end_time[machine_id, current_index] = current_end_time\n",
        "            X_schedule_plan[machine_id, current_index, :] = [\n",
        "                job_id, job_position]\n",
        "            index_machine[machine_id] += 1\n",
        "            index_job[job_id] += 1\n",
        "\n",
        "        self.M_start_time = M_start_time\n",
        "        self.M_end_time = M_end_time\n",
        "        self.X_schedule_plan = X_schedule_plan\n",
        "        return np.max(M_end_time)\n",
        "\n",
        "    def PlotResult(self, num=0):\n",
        "        # plot function for the gant map\n",
        "\n",
        "        colorbox = ['yellow', 'whitesmoke', 'lightyellow',\n",
        "                    'khaki', 'silver', 'pink', 'lightgreen', 'orange', 'grey', 'r', 'brown']\n",
        "\n",
        "        for i in range(100):\n",
        "            colorArr = ['1', '2', '3', '4', '5', '6', '7',\n",
        "                        '8', '9', 'A', 'B', 'C', 'D', 'E', 'F']\n",
        "            color = \"\"\n",
        "            for i in range(6):\n",
        "                color += colorArr[random.randint(0, 14)]\n",
        "            colorbox.append(\"#\"+color)\n",
        "\n",
        "        fig = plt.figure(figsize=(7, 4))\n",
        "        for i in range(self.number_machine):\n",
        "            # number_of_mashine:\n",
        "            for j in range(self.number_job):\n",
        "                # number_of_job:\n",
        "                # % read the start time point\n",
        "                mPoint1 = self.M_start_time[i, j]\n",
        "                mPoint2 = self.M_end_time[i, j]  # % read the end time point\n",
        "                mText = i + 1.5  # % read the index of machine\n",
        "                PlotRec(mPoint1, mPoint2, mText)  # % plot subfunction\n",
        "                Word = str(self.X_schedule_plan[i, j, 0]+1) + '.' + str(\n",
        "                    self.X_schedule_plan[i, j, 1]+1)  # % read machine id\n",
        "\n",
        "                x1, x2, x3, x4 = mPoint1, mPoint2, mPoint2, mPoint1\n",
        "                y1, y2, y3, y4 = mText-0.8, mText-0.8, mText, mText\n",
        "                plt.fill([x1, x2, x3, x4], [y1, y2, y3, y4],\n",
        "                         color=colorbox[self.X_schedule_plan[i, j, 0]])\n",
        "\n",
        "                plt.text(0.5*mPoint1+0.5*mPoint2-3.5, mText-0.5, Word)\n",
        "\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Machine')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('gant.png')\n",
        "        plt.close()\n",
        "\n",
        "    def Print_info(self):\n",
        "        # print the problem infomation\n",
        "\n",
        "        print('order')\n",
        "        print(self.M_processing_order)\n",
        "        print('time')\n",
        "        print(self.M_processing_time)\n",
        "        print('start time')\n",
        "        print(self.M_start_time)\n",
        "        print('end time')\n",
        "        print(self.M_end_time)\n",
        "        print('X')\n",
        "        print(self.X_schedule_plan)\n",
        "\n",
        "    def GetFeature(self, job_id, job_position):\n",
        "        # get the feature of one position of one job\n",
        "        # readers can change the feature to get a more powerful model\n",
        "        # raw features\n",
        "        machine_id = self.M_processing_order[job_id, job_position]\n",
        "        job_time_need = np.sum(self.M_processing_time, axis=1)\n",
        "        current_time_use = self.M_processing_time[job_id, job_position]\n",
        "        machine_endtime = np.max(self.M_end_time, axis=1)\n",
        "        job_endtime = np.sum(self.M_processing_time[job_id, :job_position])\n",
        "        job_alltime = np.sum(self.M_processing_time[job_id, :])\n",
        "\n",
        "        if job_position == 0:\n",
        "            frac_currentend_othermachineave = 0.5\n",
        "            frac_currentend_otherjobave = 0.5\n",
        "            frac_currentendplusthisposition_othermachineave = 1\n",
        "            schedule_finish_station = 0\n",
        "\n",
        "            frac_jobposition_jobtime = 1\n",
        "            frac_jobposition_totaltime = 1\n",
        "        else:\n",
        "            frac_currentend_othermachineave = (\n",
        "                0.1+machine_endtime[machine_id]) / (0.1+np.average(machine_endtime))\n",
        "            frac_currentendplusthisposition_othermachineave = (\n",
        "                machine_endtime[machine_id]+current_time_use)/np.average(machine_endtime)\n",
        "            schedule_finish_station = np.count_nonzero(\n",
        "                self.M_end_time)/self.number_machine/self.number_job\n",
        "\n",
        "            frac_currentend_otherjobave = (0.1+job_endtime) / (0.1+job_alltime)\n",
        "            frac_jobposition_jobtime = current_time_use/job_time_need[job_id]\n",
        "            frac_jobposition_totaltime = current_time_use/np.sum(job_time_need)\n",
        "        # feature choose\n",
        "        features = []\n",
        "        # current features\n",
        "        features.append(frac_currentend_othermachineave)\n",
        "        features.append(frac_currentend_otherjobave)\n",
        "        # features.append(frac_currentendplusthisposition_othermachineave)\n",
        "        # features.append(schedule_finish_station)\n",
        "        # # stable features\n",
        "        # features.append(frac_jobposition_jobtime)\n",
        "        # features.append(frac_jobposition_totaltime)\n",
        "        self.number_features = len(features)\n",
        "        if job_position == -1:\n",
        "            features = [-1] * self.number_features\n",
        "        return features\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "    # class for deep q learning agent\n",
        "\n",
        "    def __init__(self, state_size, action_size, number_job, number_feature):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.number_job = number_job\n",
        "        self.number_feature = number_feature\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95  # discount rate\n",
        "        self.epsilon = 0.9  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.0005\n",
        "        self.model = self._build_subproblem_model()  # build the model\n",
        "\n",
        "    def _build_subproblem_model(self):\n",
        "        # to build the whole model for jobshop\n",
        "\n",
        "        basic_model = self._submodel()\n",
        "\n",
        "        output_list = []\n",
        "        input_list = []\n",
        "        for i in range(self.number_job):\n",
        "            input_list.append(Input(shape=(self.number_feature,)))\n",
        "            output_list.append(basic_model(input_list[i]))\n",
        "\n",
        "        concatenated = keras.layers.concatenate(output_list)\n",
        "        out = Dense(self.action_size, activation='linear')(concatenated)\n",
        "        model = Model(input_list, out)\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def _submodel(self):\n",
        "        # the sub model called by function  _build_subproblem_model\n",
        "\n",
        "        model = Sequential(name='basic_model')\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(1, activation='linear'))\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def _easymodel(self):\n",
        "        # the easy ann model, not used in this method\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        # remember the information of this step\n",
        "\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        # let the agent make a decision\n",
        "        # choose a job to process in current state\n",
        "\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])  # returns action\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        # replay the history and train the model\n",
        "\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma *\n",
        "                          np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        # load the model\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        # save the model\n",
        "        self.model.save_weights(name)\n",
        "\n",
        "class DQNAgent_Random:\n",
        "    # class for deep q learning agent\n",
        "    def __init__(self, state_size, action_size, number_job, number_feature):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.number_job = number_job\n",
        "        self.number_feature = number_feature\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95  # discount rate\n",
        "        self.epsilon = 0.9  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.0005\n",
        "        self.model = self._build_subproblem_model()  # build the model\n",
        "\n",
        "    def _build_subproblem_model(self):\n",
        "        # to build the whole model for jobshop\n",
        "\n",
        "        basic_model = self._submodel()\n",
        "\n",
        "        output_list = []\n",
        "        input_list = []\n",
        "        for i in range(self.number_job):\n",
        "            input_list.append(Input(shape=(self.number_feature,)))\n",
        "            output_list.append(basic_model(input_list[i]))\n",
        "\n",
        "        concatenated = keras.layers.concatenate(output_list)\n",
        "        out = Dense(self.action_size, activation='linear')(concatenated)\n",
        "        model = Model(input_list, out)\n",
        "        model.compile(loss='mse',optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def _submodel(self):\n",
        "        # the sub model called by function  _build_subproblem_model\n",
        "\n",
        "        model = Sequential(name='basic_model')\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.number_feature, activation='relu'))\n",
        "        model.add(Dense(24, activation='relu'))\n",
        "        model.add(Dense(1, activation='linear'))\n",
        "        model.compile(loss='mse',optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def _easymodel(self):\n",
        "        # the easy ann model, not used in this method\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(self.action_size, activation='linear'))\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        # remember the information of this step\n",
        "\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        # let the agent make a decision\n",
        "        # choose a job to process in current state\n",
        "\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(act_values[0])  # returns action\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        # replay the history and train the model\n",
        "\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = (reward + self.gamma *\n",
        "                          np.amax(self.model.predict(next_state)[0]))\n",
        "            target_f = self.model.predict(state)\n",
        "            target_f[0][action] = target\n",
        "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        # load the model\n",
        "        self.model.load_weights(name)\n",
        "\n",
        "    def save(self, name):\n",
        "        # save the model\n",
        "        self.model.save(name)# .save_weights(name)\n",
        "def PlotRec(mPoint1, mPoint2, mText):\n",
        "    # sub function to plot a box in figure\n",
        "\n",
        "    vPoint = np.zeros((4, 2))\n",
        "    vPoint[0, :] = [mPoint1, mText-0.8]\n",
        "    vPoint[1, :] = [mPoint2, mText-0.8]\n",
        "    vPoint[2, :] = [mPoint1, mText]\n",
        "    vPoint[3, :] = [mPoint2, mText]\n",
        "    plt.plot([vPoint[0, 0], vPoint[1, 0]], [vPoint[0, 1], vPoint[1, 1]], 'k')\n",
        "    plt.plot([vPoint[0, 0], vPoint[2, 0]], [vPoint[0, 1], vPoint[2, 1]], 'k')\n",
        "    plt.plot([vPoint[1, 0], vPoint[3, 0]], [vPoint[1, 1], vPoint[3, 1]], 'k')\n",
        "    plt.plot([vPoint[2, 0], vPoint[3, 0]], [vPoint[2, 1], vPoint[3, 1]], 'k')\n",
        "\n",
        "def train():\n",
        "    number_job = 5\n",
        "    number_machine = 4\n",
        "    number_feature =2\n",
        "    state_size = number_job * number_feature\n",
        "    action_size = number_job\n",
        "    agent = DQNAgent(state_size, action_size, number_job, number_feature)\n",
        "    #agent.load()\n",
        "    batch_size = number_job * number_machine * 10\n",
        "    history = []\n",
        "    successnumber = 0\n",
        "    EPISODES=100\n",
        "    # the main loop for each job shop problem\n",
        "    for e in range(EPISODES):\n",
        "        problem = JobShop(number_machine, number_job, 15, 30, False)\n",
        "        state, score, done = problem.Step()\n",
        "        action_list = []\n",
        "        oldscore = 0\n",
        "        score = 0\n",
        "        # the sub loop for each step of the problem\n",
        "        for time in range(number_job * number_machine):\n",
        "            action = agent.act(state)\n",
        "            next_state, score, done = problem.Step(action)\n",
        "            reward = oldscore - score + 15 if not done else -1000\n",
        "            oldscore = score\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            if done:\n",
        "                if time >= number_job * number_machine - 1:\n",
        "                    successnumber += 1\n",
        "                break\n",
        "            # record the history\n",
        "            action_list.append(action)\n",
        "        if len(agent.memory) > batch_size:\n",
        "            agent.replay(batch_size)\n",
        "        # problem.PlotResult()\n",
        "        if e % 10 == 0:\n",
        "            print(\"loop : {}/{},  makespan: {} success: {} / 10, e: {:.2}\".format(e, EPISODES, score, successnumber, agent.epsilon))\n",
        "            print(action_list, len(action_list))\n",
        "            successnumber = 0\n",
        "            agent.save(\"models/jobshop-dqn-new.h5\")\n",
        "        print(f'Schedule:{problem.schedule_line}')\n",
        "\n",
        "train()\n",
        "# problem = JobShop(4, 5, 15, 30, bool_random = True)\n",
        "# print(problem.MeasurementAction([[2, 0], [0, 0], [3, 0], [4, 0], [1, 0], [0, 1], [3, 1], [2, 1], [1, 1], [4, 1], [3, 2], [2, 2], [0, 2], [4, 2], [1, 2], [3, 3], [0, 3], [4, 3], [2, 3], [1, 3]]))"
      ],
      "metadata": {
        "id": "S2uhKJkZOHsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}