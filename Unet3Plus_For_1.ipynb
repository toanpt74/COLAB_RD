{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/Unet3Plus_For_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEukNkjRvcMO",
        "outputId": "fc6ce3b1-c2cc-4e33-dcb8-307c757e5ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.metrics\n",
        "from keras.layers import Conv2DTranspose, Activation, BatchNormalization, Conv2D, concatenate,Input,MaxPool2D, UpSampling2D,MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras import activations\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def LoadDataToTrain(input_shape=(256,256,1), path='', test_ratio=0.2, Use_Region = False):\n",
        "    images_path = path\n",
        "    X_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'train')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    Y_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'label')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "\n",
        "    train_img_paths, test_img_paths, train_label_paths, test_label_paths = train_test_split(X_path, Y_path,test_size=0.2)\n",
        "\n",
        "    if Use_Region == True:\n",
        "        X_train = loadImageCrop(train_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_train = loadImageCrop(train_label_paths, input_shape=input_shape, islabel=1)\n",
        "        X_test = loadImageCrop(test_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_test = loadImageCrop(test_label_paths, input_shape=input_shape, islabel=1)\n",
        "    else:\n",
        "        X_train = loadImages(train_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_train = loadImages(train_label_paths, input_shape=input_shape, islabel=1)\n",
        "        X_test = loadImages(test_img_paths, input_shape=input_shape, islabel=0)\n",
        "        Y_test = loadImages(test_label_paths, input_shape=input_shape, islabel=1)\n",
        "    Y_train = np.where(Y_train < 1, 0.0, 1.0)\n",
        "    Y_test = np.where(Y_test < 1, 0.0, 1.0)\n",
        "\n",
        "    X_test = X_test.reshape((X_test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_test = Y_test.reshape((Y_test.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    X_train = X_train.reshape((X_train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    Y_train = Y_train.reshape((Y_train.shape[0], input_shape[0], input_shape[1], 1))\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "def LoadDataFromImage(input_shape=(256,256,1), path='', test_ratio=0.2):\n",
        "    images_path = path\n",
        "\n",
        "    X_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'train')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    Y_path = [os.path.join(root, file) for root, _, files in\n",
        "              os.walk(os.path.join(images_path, 'label')) for file in files if\n",
        "              (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    #Xu dung crop vung anh\n",
        "    #X = loadImageCrop(X_path, train_region=train_region, input_shape=input_shape, islabel=0)\n",
        "    #Y = loadImageCrop(Y_path, train_region=train_region, input_shape=input_shape, islabel=1)\n",
        "    X = loadImages(X_path, input_shape=input_shape, islabel=0)\n",
        "    Y = loadImages(Y_path, input_shape=input_shape, islabel=1)\n",
        "    Y = np.where(Y < 0.5, 0.0, 1.0)\n",
        "    return (X,Y)  #(X_train, Y_train), (X_test, Y_test)\n",
        "def loadImages(images_path, input_shape, islabel=0):\n",
        "    data = []\n",
        "    print(\"**************\")\n",
        "    for file in images_path:\n",
        "        print(\"Load file:\" + file)\n",
        "        im = cv2.imread(file)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        im = cv2.resize(im, (input_shape[1], input_shape[0]))\n",
        "        im = np.array(im)\n",
        "        im = im.astype('float32')\n",
        "        temp = im / 255.0\n",
        "        if islabel ==1 :\n",
        "            print(temp.shape)\n",
        "            print(np.sum(temp))\n",
        "        data.append(temp)\n",
        "    X = np.array(data)\n",
        "    return X\n",
        "def loadImageCrop(images_path, train_region, input_shape, islabel=0):\n",
        "    data = []\n",
        "\n",
        "    for file in images_path:\n",
        "        print(\"Load file:\" + file)\n",
        "        im = cv2.imread(file)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        crop_img = im[train_region[1]:train_region[1] + train_region[3],\n",
        "                   train_region[0]:train_region[0] + train_region[2]]\n",
        "\n",
        "        crop_img = cv2.resize(crop_img, (input_shape[1], input_shape[0]))\n",
        "\n",
        "        crop_img = np.array(crop_img)\n",
        "        crop_img = crop_img.astype('float32')\n",
        "        temp = crop_img / 255.0\n",
        "        if islabel ==1 and np.sum(temp) <500:\n",
        "            temp[:,:]=0.0\n",
        "\n",
        "        data.append(temp)\n",
        "    X = np.array(data)\n",
        "    return X\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1e-6\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    dice_loss= (2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)\n",
        "\n",
        "    #dice_loss = (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
        "    return  1- dice_loss\n",
        "def IoULoss(targets, inputs):\n",
        "    # flatten label and prediction tensors\n",
        "    # inputs = K.flatten(inputs)\n",
        "    # targets = K.flatten(targets)\n",
        "    smooth = 1e-6\n",
        "    ##intersection = K.sum(K.dot(targets, inputs))\n",
        "    intersection = K.sum(targets*inputs)\n",
        "    total = K.sum(targets) + K.sum(inputs)\n",
        "    union = total - intersection\n",
        "    IoU = (intersection + smooth) / (union + smooth)\n",
        "    return 1-IoU\n",
        "\n",
        "def conv_block(x, filters=16, kernel_size=(3, 3), padding='same', strides=(1, 1), dilation_rate=(1, 1), n=2,name='Conv', is_bn=True, is_relu=True):\n",
        "    for i in range(1, n + 1):\n",
        "        y = Conv2D(filters=filters, kernel_size=kernel_size, kernel_initializer='he_normal', padding=padding, strides=strides,\n",
        "        dilation_rate=dilation_rate, name='{0}_{1}'.format(name, i))(x)\n",
        "        if is_bn:\n",
        "            y = BatchNormalization(name='BN_' + name)(y)\n",
        "        if is_relu:\n",
        "            y = Activation('relu', name='AC_' + name)(y)\n",
        "    return y\n",
        "\n",
        "def conv_block_small(x, filters=16, kernel_size=(3, 3), padding='same', strides=(1, 1), dilation_rate=(2, 2),name='Conv'):\n",
        "    y = Conv2D(filters=filters, kernel_size=kernel_size, kernel_initializer='he_normal', padding=padding,\n",
        "    strides=strides, dilation_rate=dilation_rate, name=name)(x)\n",
        "    y = BatchNormalization(name='BN_' + name)(y)\n",
        "    y = Activation('relu', name='AC_' + name)(y)\n",
        "    return y\n",
        "def wide_block(x, filters=16, name='Conv'):\n",
        "    en1 = conv_block_small(x, filters=2 ** filters, kernel_size=(3, 3), name=name + 'en1', dilation_rate=(1, 1))  # 320*320*64\n",
        "    en2 = conv_block_small(x, filters=2 ** (filters + 1), kernel_size=(3, 3), name=name + 'en2', dilation_rate=(2, 2))\n",
        "    en3 = conv_block_small(x, filters=2 ** (filters + 2), kernel_size=(3, 3), name=name + 'en3', dilation_rate=(3, 3))\n",
        "    e = concatenate(inputs=[en1, en2, en3], axis=-1)\n",
        "    e = conv_block_small(x=e, filters=2 ** (filters + 2), kernel_size=(1, 1), name=name + 'e', dilation_rate=(1, 1))\n",
        "    return e\n",
        "\n",
        "filters = [2, 3, 4, 5, 6]\n",
        "\n",
        "def Assy_Model(INPUT_SHAPE, OUTPUT_CHANNELS):\n",
        "    input_layer = Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "    \"\"\" Encoder\"\"\"\n",
        "    # block 1\n",
        "    e1 = wide_block(x=input_layer, filters=filters[0], name='Enc_{0}_1'.format(filters[0]))\n",
        "    # block 2\n",
        "    e2 = MaxPooling2D(pool_size=(2, 2))(e1)  # 160*160*64\n",
        "    e2 = wide_block(e2, filters[1], name='Enc_{0}_1'.format(filters[1]))\n",
        "    # block 3\n",
        "    e3 = MaxPooling2D(pool_size=(2, 2))(e2)  # 80*80*128\n",
        "    e3 = wide_block(e3, filters[2], name='Enc_{0}_1'.format(filters[2]))\n",
        "    # block 4\n",
        "    e4 = MaxPooling2D(pool_size=(2, 2))(e3)  # 40*40*256\n",
        "    e4 = wide_block(e4, filters[3], name='Enc_{0}_1'.format(filters[3]))\n",
        "    # block 5\n",
        "    e5 = MaxPooling2D(pool_size=(2, 2))(e4)  # 20*20*512\n",
        "    e5 = wide_block(e5, filters[4], name='Enc_{0}_1'.format(filters[4]))\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    cat_channels = 32\n",
        "    upsample_channels = 64\n",
        "    \"\"\" d4 \"\"\"\n",
        "    e1_d4 = MaxPooling2D(pool_size=(8, 8))(e1)\n",
        "    e1_d4 = conv_block(e1_d4, cat_channels, n=1, name='Dec_e1_d4_1')\n",
        "    e2_d4 = MaxPooling2D(pool_size=(4, 4))(e2)\n",
        "    e2_d4 = conv_block(e2_d4, cat_channels, n=1, name='Dec_e2_d4_1')\n",
        "    e3_d4 = MaxPooling2D(pool_size=(2, 2))(e3)\n",
        "    e3_d4 = conv_block(e3_d4, cat_channels, n=1, name='Dec_e3_d4_1')\n",
        "    e4_d4 = conv_block(e4, cat_channels, n=1)\n",
        "    e5_d4 = UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)\n",
        "    e5_d4 = conv_block(e5_d4, cat_channels, n=1, name='Dec_e5_d4_1')\n",
        "    d4 = concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
        "    d4 = conv_block(d4, upsample_channels, n=1, name='Dec_d4_1')\n",
        "    \"\"\" d3 \"\"\"\n",
        "    e1_d3 = MaxPooling2D(pool_size=(4, 4))(e1)\n",
        "    e1_d3 = conv_block(e1_d3, cat_channels, n=1, name='Dec_e1_d3_1')\n",
        "    e2_d3 = MaxPooling2D(pool_size=(2, 2))(e2)\n",
        "    e2_d3 = conv_block(e2_d3, cat_channels, n=1, name='Dec_e2_d3_1')\n",
        "    e3_d3 = conv_block(e3, cat_channels, n=1, name='Dec_e3_d3_1')\n",
        "    e4_d3 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)\n",
        "    e4_d3 = conv_block(e4_d3, cat_channels, n=1, name='Dec_e4_d3_1')\n",
        "    e5_d3 = UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)\n",
        "    e5_d3 = conv_block(e5_d3, cat_channels, n=1, name='Dec_e5_d3_1')\n",
        "    d3 = concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
        "    d3 = conv_block(d3, upsample_channels, n=1, name='Dec_d3_1')\n",
        "    \"\"\" d2 \"\"\"\n",
        "    e1_d2 = MaxPooling2D(pool_size=(2, 2))(e1)\n",
        "    e1_d2 = conv_block(e1_d2, cat_channels, n=1, name='Dec_e1_d2_1')\n",
        "    e2_d2 = conv_block(e2, cat_channels, n=1, name='Dec_e2_d2_1')\n",
        "    d3_d2 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)\n",
        "    d3_d2 = conv_block(d3_d2, cat_channels, n=1, name='Dec_d3_d2_1')\n",
        "    d4_d2 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)\n",
        "    d4_d2 = conv_block(d4_d2, cat_channels, n=1, name='Dec_d4_d2_1')\n",
        "    e5_d2 = UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)\n",
        "    e5_d2 = conv_block(e5_d2, cat_channels, n=1, name='Dec_e5_d2_1')\n",
        "    d2 = concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
        "    d2 = conv_block(d2, upsample_channels, n=1, name='Dec_d2_1')\n",
        "    \"\"\" d1 \"\"\"\n",
        "    e1_d1 = conv_block(e1, cat_channels, n=1, name='Dec_e1_d1_1')\n",
        "    d2_d1 = UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)\n",
        "    d2_d1 = conv_block(d2_d1, cat_channels, n=1, name='Dec_d2_d1_1')\n",
        "    d3_d1 = UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)\n",
        "    d3_d1 = conv_block(d3_d1, cat_channels, n=1, name='Dec_d3_d1_1')\n",
        "    d4_d1 = UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)\n",
        "    d4_d1 = conv_block(d4_d1, cat_channels, n=1, name='Dec_d4_d1_1')\n",
        "    e5_d1 = UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)\n",
        "    e5_d1 = conv_block(e5_d1, cat_channels, n=1, name='Dec_e5_d1_1')\n",
        "    d1 = concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1])\n",
        "    d1 = conv_block(d1, upsample_channels, n=1, name='Dec_d1_1')\n",
        "    # last layer does not have batchnorm and relu\n",
        "    d = conv_block(d1, OUTPUT_CHANNELS, n=1, is_bn=False, is_relu=False, name='Dec_d_1')\n",
        "    if OUTPUT_CHANNELS == 1:\n",
        "        output = activations.sigmoid(d)\n",
        "    else:\n",
        "        output = activations.softmax(d)\n",
        "    return Model(inputs=input_layer, outputs=output, name='UNet_3Plus')\n",
        "\n",
        "epochs=201\n",
        "BATCH_SIZE=1\n",
        "OUTPUT_CHANNELS=1\n",
        "INPUT_SHAPE = [512, 512, 1]\n",
        "OPTIMIZER = tf.keras.optimizers.Adam()\n",
        "path= r'E:\\data'\n",
        "model_save_path = r'E:\\ToanPT\\1.Code_train_Unet\\models\\unet'\n",
        "model = Assy_Model(INPUT_SHAPE, OUTPUT_CHANNELS)\n",
        "model.compile(optimizer=OPTIMIZER, loss = 'binary_crossentropy', metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "#model.compile(optimizer=OPTIMIZER, loss=IoULoss,metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "                   ModelCheckpoint(\n",
        "                       os.path.join(model_save_path,\n",
        "                     'model-assy-{epoch:03d}--{loss:.6f}-{accuracy:.6f}--{val_loss:.6f}-{val_accuracy:.6f}.h5'),\n",
        "                       monitor='val_accuracy', save_best_only=False,\n",
        "                       save_weights_only=False, period=5, mode='auto', verbose=0),\n",
        "                  ]\n",
        "(x_train, y_train), (x_test, y_test) = LoadDataToTrain(input_shape=INPUT_SHAPE,path=path, Use_Region=False)\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), verbose=1, epochs=epochs, batch_size=BATCH_SIZE, shuffle=True, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "pqaJdfeiwFnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
