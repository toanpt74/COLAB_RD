{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/Unet3plus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.regularizers\n",
        "import tensorflow as tf\n",
        "import keras as k\n",
        "from keras.api.keras import activations\n",
        "from keras.layers import Conv2D, Activation, Input, MaxPooling2D, BatchNormalization, Conv2DTranspose, concatenate, UpSampling2D, MaxPool2D\n",
        "\n",
        "\n",
        "def conv_block(x, filters =16, kernel_size=(3,3), strides=(1,1),padding='same', is_bn=True, is_relu=True, n=2):\n",
        "    for i in range(1, n+1):\n",
        "        x = Conv2D(filters= filters, kernel_size= kernel_size, strides=strides, padding=padding,\n",
        "               kernel_regularizer=keras.regularizers.l2(1e-4), kernel_initializer=\"he_normal\")(x)\n",
        "        if is_bn:\n",
        "            x = BatchNormalization()(x)\n",
        "        if is_relu:\n",
        "            x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, filters):\n",
        "    x = conv_block(inputs, filters)\n",
        "    p = MaxPooling2D((2,2))(x)\n",
        "    return x, p\n",
        "def decoder_block(inputs,skip_features ,num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
        "    x = concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def UNet_3Plus(INPUT_SHAPE, OUTPUT_CHANNELS):\n",
        "    filters = [64, 128, 256, 512, 1024]\n",
        "    inputs = Input(shape=INPUT_SHAPE, name='input_shape')\n",
        "    #encoder\n",
        "    #block 1\n",
        "    e1, p1 = encoder_block(inputs, filters=filters[0])\n",
        "    # block 2\n",
        "    e2, p2 = encoder_block(p1, filters=filters[1])\n",
        "    # block 3\n",
        "    e3, p3 = encoder_block(p2, filters=filters[2])\n",
        "    #block 4\n",
        "\n",
        "    e4, p4 = encoder_block(p3, filters=filters[3])\n",
        "    #block 5 Bridge\n",
        "\n",
        "    e5 = conv_block(p4, filters[4])\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    cat_channels = filters[0]\n",
        "    cat_blocks = len(filters)\n",
        "    upsample_channels = cat_blocks * cat_channels\n",
        "    \"\"\"d4\"\"\"\n",
        "    e1_d4 = MaxPool2D(pool_size=(8, 8))(e1)\n",
        "    e1_d4 = conv_block(e1_d4, cat_channels, n=1)\n",
        "\n",
        "    e2_d4 = MaxPool2D(pool_size=(4, 4))(e2)\n",
        "    e2_d4 = conv_block(e2_d4, cat_channels, n=1)\n",
        "\n",
        "    e3_d4 = MaxPool2D(pool_size=(2, 2))(e3)\n",
        "    e3_d4 = conv_block(e3_d4, cat_channels, n=1)\n",
        "\n",
        "    e4_d4 = conv_block(e4, cat_channels, n=1)\n",
        "\n",
        "    e5_d4 = UpSampling2D(size=(2, 2), interpolation='bilinear')(e5)\n",
        "    e5_d4 = conv_block(e5_d4, filters=cat_channels, n=1)\n",
        "\n",
        "    d4 = concatenate([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
        "    d4 = conv_block(d4, filters=upsample_channels, n=1)\n",
        "\n",
        "    \"\"\" d3 \"\"\"\n",
        "    e1_d3 = k.layers.MaxPool2D(pool_size=(4, 4))(e1)  # 320*320*64 --> 80*80*64\n",
        "    e1_d3 = conv_block(e1_d3, cat_channels, n=1)  # 80*80*64 --> 80*80*64\n",
        "\n",
        "    e2_d3 = k.layers.MaxPool2D(pool_size=(2, 2))(e2)  # 160*160*256 --> 80*80*256\n",
        "    e2_d3 = conv_block(e2_d3, cat_channels, n=1)  # 80*80*256 --> 80*80*64\n",
        "\n",
        "    e3_d3 = conv_block(e3, cat_channels, n=1)  # 80*80*512 --> 80*80*64\n",
        "\n",
        "    e4_d3 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d4)  # 40*40*320 --> 80*80*320\n",
        "    e4_d3 = conv_block(e4_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    e5_d3 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(e5)  # 20*20*320 --> 80*80*320\n",
        "    e5_d3 = conv_block(e5_d3, cat_channels, n=1)  # 80*80*320 --> 80*80*64\n",
        "\n",
        "    d3 = k.layers.concatenate([e1_d3, e2_d3, e3_d3, e4_d3, e5_d3])\n",
        "    d3 = conv_block(d3, upsample_channels, n=1)  # 80*80*320 --> 80*80*320\n",
        "\n",
        "    \"\"\" d2 \"\"\"\n",
        "    e1_d2 = k.layers.MaxPool2D(pool_size=(2, 2))(e1)  # 320*320*64 --> 160*160*64\n",
        "    e1_d2 = conv_block(e1_d2, cat_channels, n=1)  # 160*160*64 --> 160*160*64\n",
        "\n",
        "    e2_d2 = conv_block(e2, cat_channels, n=1)  # 160*160*256 --> 160*160*64\n",
        "\n",
        "    d3_d2 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d3)  # 80*80*320 --> 160*160*320\n",
        "    d3_d2 = conv_block(d3_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d4_d2 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d4)  # 40*40*320 --> 160*160*320\n",
        "    d4_d2 = conv_block(d4_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    e5_d2 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(e5)  # 20*20*320 --> 160*160*320\n",
        "    e5_d2 = conv_block(e5_d2, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d2 = k.layers.concatenate([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
        "    d2 = conv_block(d2, upsample_channels, n=1)  # 160*160*320 --> 160*160*320\n",
        "\n",
        "    \"\"\" d1 \"\"\"\n",
        "    e1_d1 = conv_block(e1, cat_channels, n=1)  # 320*320*64 --> 320*320*64\n",
        "\n",
        "    d2_d1 = k.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(d2)  # 160*160*320 --> 320*320*320\n",
        "    d2_d1 = conv_block(d2_d1, cat_channels, n=1)  # 160*160*320 --> 160*160*64\n",
        "\n",
        "    d3_d1 = k.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(d3)  # 80*80*320 --> 320*320*320\n",
        "    d3_d1 = conv_block(d3_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d4_d1 = k.layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(d4)  # 40*40*320 --> 320*320*320\n",
        "    d4_d1 = conv_block(d4_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    e5_d1 = k.layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(e5)  # 20*20*320 --> 320*320*320\n",
        "    e5_d1 = conv_block(e5_d1, cat_channels, n=1)  # 320*320*320 --> 320*320*64\n",
        "\n",
        "    d1 = k.layers.concatenate([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1, ])\n",
        "    d1 = conv_block(d1, upsample_channels, n=1)  # 320*320*320 --> 320*320*320\n",
        "\n",
        "    # last layer does not have batchnorm and relu\n",
        "    d = conv_block(d1, OUTPUT_CHANNELS, n=1, is_bn=False, is_relu=False)\n",
        "\n",
        "    if OUTPUT_CHANNELS == 1:\n",
        "        output = k.activations.sigmoid(d)\n",
        "    else:\n",
        "        output = k.activations.softmax(d)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=output, name='UNet_3Plus')\n",
        "\n",
        "INPUT_SHAPE = [256, 256, 1]\n",
        "OUTPUT_CHANNELS = 1\n",
        "model = UNet_3Plus(INPUT_SHAPE, OUTPUT_CHANNELS)\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "S2uhKJkZOHsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}