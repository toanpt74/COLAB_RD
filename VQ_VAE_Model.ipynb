{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/VQ_VAE_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEukNkjRvcMO",
        "outputId": "fc6ce3b1-c2cc-4e33-dcb8-307c757e5ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from distutils.command.install_egg_info import install_egg_info\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from keras.layers import BatchNormalization, Activation, Conv2D, Add, Dropout\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "COL = 128 #width\n",
        "ROW = 256 #height\n",
        "INPUT_SHAPE=(COL, ROW, 1,)\n",
        "datapath=r'E:\\ToanPT'\n",
        "\n",
        "def LoadDataToTrain(input_shape=(256,256,1), path='', test_ratio=0.2, Use_Region = False):\n",
        "    images_path = path\n",
        "\n",
        "    image_file_list = os.listdir(images_path)\n",
        "\n",
        "    X_path = [os.path.join(images_path, fname) for fname in image_file_list]\n",
        "    random.shuffle(X_path)\n",
        "\n",
        "\n",
        "\n",
        "    # X_path = [os.path.join(root, file) for root, _, files in\n",
        "    #           os.walk(os.path.join(images_path, 'train')) for file in files if\n",
        "    #           (file.endswith('.jpg') or file.endswith('.bmp') or file.endswith('.png'))]\n",
        "    X_train = loadImages(X_path, input_shape=input_shape, islabel=0)\n",
        "    return X_train, X_path\n",
        "def loadImages(images_path, input_shape, islabel=0):\n",
        "    data = []\n",
        "    print(\"**************\")\n",
        "    for file in images_path:\n",
        "        print(\"Load file:\" + file)\n",
        "        im = cv2.imread(file)\n",
        "        d = len(im.shape)\n",
        "        if d == 3:\n",
        "            im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
        "        # Crop Image\n",
        "        im = cv2.resize(im, (input_shape[1], input_shape[0]))\n",
        "        im = np.array(im)\n",
        "        im = im.astype('float32')\n",
        "        temp = im / 255.0\n",
        "        if islabel ==1 :\n",
        "            print(temp.shape)\n",
        "            print(np.sum(temp))\n",
        "        data.append(temp)\n",
        "    X = np.array(data)\n",
        "    return X\n",
        "\n",
        "class VectorQuantizer(layers.Layer):\n",
        "    def __init__(self, num_embeddings, embedding_dim, beta=0.25, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.beta = beta\n",
        "        w_init = tf.random_uniform_initializer()\n",
        "        self.embeddings = tf.Variable(\n",
        "            initial_value=w_init(shape=(self.embedding_dim, self.num_embeddings), dtype=\"float32\"),\n",
        "            trainable=True,name=\"embeddings_vqvae\",)\n",
        "    def call(self, x):\n",
        "        input_shape = tf.shape(x)\n",
        "        flattened = tf.reshape(x, [-1, self.embedding_dim])\n",
        "        # Quantization.\n",
        "        encoding_indices = self.get_code_indices(flattened)\n",
        "        encodings = tf.one_hot(encoding_indices, self.num_embeddings)\n",
        "        quantized = tf.matmul(encodings, self.embeddings, transpose_b=True)\n",
        "        # Reshape the quantized values back to the original input shape\n",
        "        quantized = tf.reshape(quantized, input_shape)\n",
        "        commitment_loss = tf.reduce_mean((tf.stop_gradient(quantized) - x) ** 2)\n",
        "        codebook_loss = tf.reduce_mean((quantized - tf.stop_gradient(x)) ** 2)\n",
        "        self.add_loss(self.beta * commitment_loss + codebook_loss)\n",
        "        # Straight-through estimator.\n",
        "        quantized = x + tf.stop_gradient(quantized - x)\n",
        "        return quantized\n",
        "    def get_code_indices(self, flattened_inputs):\n",
        "        # Calculate L2-normalized distance between the inputs and the codes.\n",
        "        similarity = tf.matmul(flattened_inputs, self.embeddings)\n",
        "        distances = (\n",
        "            tf.reduce_sum(flattened_inputs ** 2, axis=1, keepdims=True)\n",
        "            + tf.reduce_sum(self.embeddings ** 2, axis=0)- 2 * similarity)\n",
        "        encoding_indices = tf.argmin(distances, axis=1)\n",
        "        return encoding_indices\n",
        "\n",
        "def encoder_conv_block(inputs,filter):\n",
        "    e1 = layers.Conv2D(filters=2**filter, kernel_size=3, strides=(1,1), padding=\"same\",dilation_rate=(1,1), activation='relu')(inputs)\n",
        "    e1 = layers.BatchNormalization()(e1)\n",
        "    e2 = layers.Conv2D(filters=2**filter+1, kernel_size=3, strides=(1,1), padding=\"same\", dilation_rate=(2, 2), activation='relu')(inputs)\n",
        "    e2 = layers.BatchNormalization()(e2)\n",
        "    e = layers.concatenate(inputs=[e1, e2], axis=-1)\n",
        "    y = layers.Conv2D(filters=2**filter+1, kernel_size=3, strides=(2,2), padding=\"same\", dilation_rate=(1, 1), activation='relu')(e)\n",
        "    return y\n",
        "def get_encoder(latent_dim=32):\n",
        "    encoder_inputs = keras.Input(shape=INPUT_SHAPE)\n",
        "    x = encoder_conv_block(encoder_inputs, filter=4)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = encoder_conv_block(inputs=x, filter=5)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = encoder_conv_block(inputs=x, filter=6)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = encoder_conv_block(inputs=x, filter=7)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = encoder_conv_block(inputs=x, filter=8)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "    #-----------------------\n",
        "    # x = layers.Conv2D(16, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "    #     encoder_inputs\n",
        "    # )\n",
        "    # x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    # x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    #\n",
        "    # x = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    #\n",
        "    # encoder_outputs = layers.Conv2D(latent_dim, 1, padding=\"same\")(x)\n",
        "    # return keras.Model(encoder_inputs, encoder_outputs, name=\"encoder\")\n",
        "def get_decoder(latent_dim=32):\n",
        "    latent_inputs = keras.Input(shape=get_encoder(latent_dim).output.shape[1:])\n",
        "    x = layers.Conv2DTranspose(filters=256, kernel_size=3, strides=2, padding='same', activation='relu')(latent_inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(filters=128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
        "    decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
        "    return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "    #---------------------\n",
        "    # x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(\n",
        "    #     latent_inputs\n",
        "    # )\n",
        "    # x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    # x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    # x = layers.Conv2DTranspose(16, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "    #\n",
        "    # decoder_outputs = layers.Conv2DTranspose(1, 3, padding=\"same\")(x)\n",
        "    # return keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "def get_vqvae(latent_dim=32, num_embeddings=64):\n",
        "    vq_layer = VectorQuantizer(num_embeddings, latent_dim, name=\"vector_quantizer\")\n",
        "    encoder = get_encoder(latent_dim)\n",
        "    decoder = get_decoder(latent_dim)\n",
        "    inputs = keras.Input(shape=INPUT_SHAPE)\n",
        "    encoder_outputs = encoder(inputs)\n",
        "    quantized_latents = vq_layer(encoder_outputs)\n",
        "    reconstructions = decoder(quantized_latents)\n",
        "    return keras.Model(inputs, reconstructions, name=\"vq_vae\")\n",
        "\n",
        "get_vqvae().summary()\n",
        "\n",
        "class VQVAETrainer(keras.models.Model):\n",
        "    def __init__(self, train_variance, latent_dim=32, num_embeddings=128, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.train_variance = train_variance\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_embeddings = num_embeddings\n",
        "        self.vqvae = get_vqvae(self.latent_dim, self.num_embeddings)\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\")\n",
        "        self.vq_loss_tracker = keras.metrics.Mean(name=\"vq_loss\")\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.vq_loss_tracker,\n",
        "        ]\n",
        "    def train_step(self, x):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Outputs from the VQ-VAE.\n",
        "            reconstructions = self.vqvae(x)\n",
        "            # Calculate the losses.\n",
        "            reconstruction_loss = (\n",
        "                tf.reduce_mean((x - reconstructions) ** 2) / self.train_variance\n",
        "            )\n",
        "            total_loss = reconstruction_loss + sum(self.vqvae.losses)\n",
        "        # Backpropagation.\n",
        "        grads = tape.gradient(total_loss, self.vqvae.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.vqvae.trainable_variables))\n",
        "        # Loss tracking.\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.vq_loss_tracker.update_state(sum(self.vqvae.losses))\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"vqvae_loss\": self.vq_loss_tracker.result(),\n",
        "        }\n",
        "    def loadWeight(self, path):\n",
        "        self.vqvae.load_weights(path)\n",
        "\n",
        "\n",
        "X_Train, X_Path = LoadDataToTrain(input_shape=INPUT_SHAPE,path=datapath, Use_Region=False)\n",
        "\n",
        "x_train_scaled = np.expand_dims(X_Train, -1)\n",
        "data_variance = np.var(X_Train)\n",
        "\n",
        "#Train model\n",
        "# vqvae_trainer = VQVAETrainer(data_variance, latent_dim=32, num_embeddings=512)\n",
        "# vqvae_trainer.compile(optimizer=keras.optimizers.Adam())\n",
        "#\n",
        "# model_save_path =r'E:\\abc'\n",
        "#\n",
        "# vqvae_trainer.fit(x_train_scaled, epochs=700, batch_size=16)\n",
        "# vqvae_trainer.vqvae.save(model_save_path +\"\\\\abc\", save_format=\"tf\")\n",
        "\n",
        "#Reconstruction\n",
        "\n",
        "\n",
        "def mse(imageA, imageB):\n",
        "    # the 'Mean Squared Error' between the two images is the\n",
        "    # sum of the squared difference between the two images;\n",
        "    # NOTE: the two images must have the same dimension\n",
        "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
        "\n",
        "    # return the MSE, the lower the error, the more \"similar\"\n",
        "    # the two images are\n",
        "    return err\n",
        "\n",
        "def Predict(model_path, file_path):\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    n = len(X_Train)\n",
        "    R = np.zeros(n)\n",
        "    Blob = np.zeros(n)\n",
        "    Path = []\n",
        "    print(f\"Number Images ={n}\")\n",
        "    NG=0\n",
        "    OK=0\n",
        "    dem=0\n",
        "    for i in range(n):\n",
        "        idx = [i]\n",
        "        test_image = X_Train[idx]\n",
        "        reconstructions_test = model.predict(test_image)\n",
        "\n",
        "        x = np.reshape(test_image, (COL, ROW))\n",
        "        y = np.reshape(reconstructions_test[0], (COL, ROW))\n",
        "        feature_score = np.power(x - y, 2)\n",
        "        outlier_map = np.where(feature_score < 0.01, 0, 255)\n",
        "        outlier_map255 = outlier_map.astype('uint8')\n",
        "        _, thresh = cv2.threshold(outlier_map255, 20, 255, cv2.THRESH_BINARY)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        outcnt = [cnt for cnt in contours if (cv2.contourArea(cnt) > 100)]\n",
        "        numblob = len(outcnt)\n",
        "        Blob[i] = numblob\n",
        "        reconstruction = reconstructions_test[0].squeeze()\n",
        "        b = mse(test_image[0], reconstruction)\n",
        "        R[i] = b\n",
        "        # if b > 0.001: #Thay spec vao day\n",
        "        if b < 0.0005: #Thay spec vao day\n",
        "             OK= OK +1\n",
        "             print(f\"OK - SCORE: {i} - {b}\")\n",
        "             print(X_Path[i])\n",
        "        else:\n",
        "            if b > 0.002:\n",
        "                print(f\"NG - SCORE: {i} - {b}\")\n",
        "                print(X_Path[i])\n",
        "                NG=NG+1\n",
        "    print(f\"OK= {OK}\")\n",
        "    print(f\"NG = {NG}\")\n",
        "    print(f\"MAX= {np.max(R)}\")\n",
        "    print(f\"MIN= {np.min(R)}\")\n",
        "    print(f\"STD= {np.std(R)}\")\n",
        "    print(f\"AVG={np.average(R)}\")\n",
        "    df = pd.DataFrame({\"Value\": R, \"NumBlob\":Blob,\"Path\": X_Path} )\n",
        "    df.to_excel(file_path, index=False)\n",
        "\n",
        "def check_image(images_path,file_path):\n",
        "    image_file_list = os.listdir(images_path)\n",
        "\n",
        "#Predict(r\"E:\\VideoClassification\\model\\abc\",r'D:\\Private_Documents\\abc.xlsx')\n",
        "\n",
        "#Test\n",
        "def CompareImages(model_path):\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    n = len(X_Train)\n",
        "    R = np.zeros(n)\n",
        "    Path = []\n",
        "    print(f\"Number Images ={n}\")\n",
        "    NG = 0\n",
        "    OK = 0\n",
        "    dem = 0\n",
        "    for i in range(10):\n",
        "        idx = [i]\n",
        "        test_image = X_Train[idx]\n",
        "        reconstructions_test = model.predict(test_image)\n",
        "        x = np.reshape(test_image, (COL, ROW))\n",
        "        y = np.reshape(reconstructions_test[0],(COL, ROW))\n",
        "        feature_score = np.power(x - y, 2)\n",
        "        outlier_map = np.where(feature_score < 0.01, 0, 255)\n",
        "        reconstruction = reconstructions_test[0].squeeze()\n",
        "        b = mse(test_image[0], reconstruction)\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(test_image[0] ,cmap='gray')# + 0.5)\n",
        "        plt.title(str(b))\n",
        "        plt.axis(\"off\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(reconstruction,cmap='gray')# + 0.5)\n",
        "        plt.title(\"Reconstructed\")\n",
        "        plt.axis(\"off\")\n",
        "        #Dem so blob\n",
        "        outlier_map255 = outlier_map.astype('uint8')\n",
        "        _, thresh = cv2.threshold(outlier_map255, 20, 255, cv2.THRESH_BINARY)\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        outcnt = [cnt for cnt in contours if (cv2.contourArea(cnt) > 100)]\n",
        "\n",
        "        numBlob = len(outcnt)\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(outlier_map, cmap='gray')  # + 0.5)\n",
        "        plt.title(f\"Score:{b}, blob :{str(numBlob)}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "CompareImages(r'E:\\abc')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pqaJdfeiwFnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}