{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/Siamese_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEukNkjRvcMO",
        "outputId": "fc6ce3b1-c2cc-4e33-dcb8-307c757e5ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "margin = 1  # Margin for constrastive loss.\n",
        "\n",
        "(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Change the data type to a floating point format\n",
        "x_train_val = x_train_val.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "\n",
        "# Keep 50% of train_val  in validation set\n",
        "x_train, x_val = x_train_val[:30000], x_train_val[30000:]\n",
        "y_train, y_val = y_train_val[:30000], y_train_val[30000:]\n",
        "del x_train_val, y_train_val\n",
        "\n",
        "def make_pairs(x, y):\n",
        "    \"\"\"Creates a tuple containing image pairs with corresponding label.\n",
        "\n",
        "    Arguments:\n",
        "        x: List containing images, each index in this list corresponds to one image.\n",
        "        y: List containing labels, each label with datatype of `int`.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing two numpy arrays as (pairs_of_samples, labels),\n",
        "        where pairs_of_samples' shape is (2len(x), 2,n_features_dims) and\n",
        "        labels are a binary array of shape (2len(x)).\n",
        "    \"\"\"\n",
        "    num_classes = max(y) + 1\n",
        "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    for idx1 in range(len(x)):\n",
        "        # add a matching example\n",
        "        x1 = x[idx1]\n",
        "        label1 = y[idx1]\n",
        "        idx2 = random.choice(digit_indices[label1])\n",
        "        x2 = x[idx2]\n",
        "        pairs += [[x1, x2]]\n",
        "        labels += [1]\n",
        "        # add a non-matching example\n",
        "        label2 = random.randint(0, num_classes - 1)\n",
        "        while label2 == label1:\n",
        "            label2 = random.randint(0, num_classes - 1)\n",
        "        idx2 = random.choice(digit_indices[label2])\n",
        "        x2 = x[idx2]\n",
        "        pairs += [[x1, x2]]\n",
        "        labels += [0]\n",
        "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
        "# make train pairs\n",
        "pairs_train, labels_train = make_pairs(x_train, y_train)\n",
        "# make validation pairs\n",
        "pairs_val, labels_val = make_pairs(x_val, y_val)\n",
        "# make test pairs\n",
        "pairs_test, labels_test = make_pairs(x_test, y_test)\n",
        "x_train_1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
        "x_train_2 = pairs_train[:, 1]\n",
        "x_val_1 = pairs_val[:, 0]  # x_val_1.shape = (60000, 28, 28)\n",
        "x_val_2 = pairs_val[:, 1]\n",
        "x_test_1 = pairs_test[:, 0]  # x_test_1.shape = (20000, 28, 28)\n",
        "x_test_2 = pairs_test[:, 1]\n",
        "\n",
        "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False, w=5, h=5):\n",
        "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
        "\n",
        "    Arguments:\n",
        "        pairs: Numpy Array, of pairs to visualize, having shape\n",
        "               (Number of pairs, 2, 28, 28).\n",
        "        to_show: Int, number of examples to visualize (default is 6)\n",
        "                `to_show` must be an integral multiple of `num_col`.\n",
        "                 Otherwise it will be trimmed if it is greater than num_col,\n",
        "                 and incremented if if it is less then num_col.\n",
        "        num_col: Int, number of images in one row - (default is 3)\n",
        "                 For test and train respectively, it should not exceed 3 and 7.\n",
        "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
        "                     (default is None)\n",
        "                     Must be passed when test=True.\n",
        "        test: Boolean telling whether the dataset being visualized is\n",
        "              train dataset or test dataset - (default False).\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define num_row\n",
        "    # If to_show % num_col != 0\n",
        "    #    trim to_show,\n",
        "    #       to trim to_show limit num_row to the point where\n",
        "    #       to_show % num_col == 0\n",
        "    #\n",
        "    # If to_show//num_col == 0\n",
        "    #    then it means num_col is greater then to_show\n",
        "    #    increment to_show\n",
        "    #       to increment to_show set num_row to 1\n",
        "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
        "\n",
        "    # `to_show` must be an integral multiple of `num_col`\n",
        "    #  we found num_row and we have num_col\n",
        "    #  to increment or decrement to_show\n",
        "    #  to make it integral multiple of `num_col`\n",
        "    #  simply set it equal to num_row * num_col\n",
        "    to_show = num_row * num_col\n",
        "\n",
        "    # Plot the images\n",
        "    fig, axes = plt.subplots(num_row, num_col, figsize=(w, h))\n",
        "    for i in range(to_show):\n",
        "\n",
        "        # If the number of rows is 1, the axes array is one-dimensional\n",
        "        if num_row == 1:\n",
        "            ax = axes[i % num_col]\n",
        "        else:\n",
        "            ax = axes[i // num_col, i % num_col]\n",
        "\n",
        "        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
        "        ax.set_axis_off()\n",
        "        if test:\n",
        "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
        "        else:\n",
        "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
        "    # if test:\n",
        "    #     plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
        "    # else:\n",
        "    #     plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
        "    plt.show()\n",
        "\n",
        "########## new custom design layer ###############################################\n",
        "\n",
        "class L1_dist(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, input_embed, val_embed):\n",
        "        sum_square = tf.math.reduce_sum(tf.math.square(input_embed - val_embed), axis=1, keepdims=True)\n",
        "        return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "input = layers.Input((28, 28, 1))\n",
        "x = tf.keras.layers.BatchNormalization()(input)\n",
        "x = layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
        "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
        "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = layers.Dense(10, activation=\"tanh\")(x)\n",
        "embedding_network = keras.Model(input, x)\n",
        "\n",
        "input_1 = layers.Input((28, 28, 1))\n",
        "input_2 = layers.Input((28, 28, 1))\n",
        "\n",
        "# As mentioned above, Siamese Network share weights between\n",
        "# tower networks (sister networks). To allow this, we will use\n",
        "# same embedding network for both tower networks.\n",
        "tower_1 = embedding_network(input_1)\n",
        "tower_2 = embedding_network(input_2)\n",
        "\n",
        "siamese_layer = L1_dist()\n",
        "siamese_layer._name = 'distance'\n",
        "###################### Here is the change ################################\n",
        "distances = siamese_layer(tower_1, tower_2)\n",
        "# merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
        "##########################################################################\n",
        "normal_layer = tf.keras.layers.BatchNormalization()(distances)\n",
        "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
        "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
        "\n",
        "\n",
        "def loss(margin=1):\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "  Arguments:\n",
        "      margin: Integer, defines the baseline for distance for which pairs\n",
        "              should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "  Returns:\n",
        "      'constrastive_loss' function with data ('margin') attached.\n",
        "  \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred, margin=1):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "      Arguments:\n",
        "          y_true: List of labels, each label is of type float32.\n",
        "          y_pred: List of predictions of same length as of y_true,\n",
        "                  each label is of type float32.\n",
        "\n",
        "      Returns:\n",
        "          A tensor containing constrastive loss as floating point value.\n",
        "      \"\"\"\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss\n",
        "\n",
        "# siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "# siamese.summary()\n",
        "#\n",
        "# history = siamese.fit(\n",
        "#     [x_train_1, x_train_2],\n",
        "#     labels_train,\n",
        "#     validation_data=([x_val_1, x_val_2], labels_val),\n",
        "#     batch_size=batch_size,\n",
        "#     epochs=epochs,\n",
        "# )\n",
        "\n",
        "# print(\"[INFO] saving siamese model...\")\n",
        "# siamese.save('models/best_model_new' + '.h5')\n",
        "# # plot the training history\n",
        "# print(\"[INFO] plotting training history...\")\n",
        "\n",
        "#Load model\n",
        "\n",
        "\n",
        "def Predict(x_test_1, x_test_2):\n",
        "    class L1_dist(Layer):\n",
        "        def __init__(self, **kwargs):\n",
        "            super().__init__()\n",
        "\n",
        "        def call(self, input_embed, val_embed):\n",
        "            sum_square = tf.math.reduce_sum(tf.math.square(input_embed - val_embed), axis=1, keepdims=True)\n",
        "            return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "    def contrastive_loss(y_true, y_pred, margin=1):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "      Arguments:\n",
        "          y_true: List of labels, each label is of type float32.\n",
        "          y_pred: List of predictions of same length as of y_true,\n",
        "                  each label is of type float32.\n",
        "\n",
        "      Returns:\n",
        "          A tensor containing constrastive loss as floating point value.\n",
        "      \"\"\"\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    print(\"[INFO] loading siamese model...\")\n",
        "    model = tf.keras.models.load_model('models/best_model_new.h5',\n",
        "                                       custom_objects={'L1_dist': L1_dist, 'contrastive_loss': contrastive_loss})\n",
        "    predictions = model.predict([x_test_1, x_test_2])\n",
        "    visualize(pairs_test, labels_test, to_show=10, predictions=predictions, test=True, w = 5, h = 5)\n",
        "    #input_img = x_test[0] / 255.0\n",
        "    # for j in range(1,10):\n",
        "    #     #for j in range(2):\n",
        "    #         #input_img = x_test[i] / 255.0\n",
        "    #         validation_img = x_test[j] / 255.0\n",
        "    #\n",
        "    #         predictions = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "    #         print(np.round(predictions[0][0], 7))\n",
        "    #         print(predictions)\n",
        "    #         # visualize(pairs_test, labels_test, to_show=1, predictions=predictions, test=True)\n",
        "    #         # print('shape 0 : ', x_test[0].shape)\n",
        "    #         # print('shape 1 : ', x_test[j].shape)\n",
        "    #         print('label 0 : ', y_test[0])\n",
        "    #         print('label 1 : ', y_test[j])\n",
        "    #         cv2.namedWindow('image1', cv2.WINDOW_FREERATIO)\n",
        "    #         cv2.namedWindow('image2', cv2.WINDOW_FREERATIO)\n",
        "    #         cv2.imshow('image1', x_test[i])\n",
        "    #         cv2.imshow('image2', x_test[j])\n",
        "    #         cv2.waitKey(0)\n",
        "    #\n",
        "    # cv2.destroyAllWindows()\n",
        "Predict(x_test_1, x_test_2)\n",
        "\n",
        "def Create_Pairs_For_Predict(index, x, y):\n",
        "    num_classes = 10\n",
        "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
        "    pairs_test = []\n",
        "    labels_test = []\n",
        "    d = 0\n",
        "    img = x[index]\n",
        "    for idx1 in range(len(x)):\n",
        "        label1 = y[index]\n",
        "        idx2 = random.choice(digit_indices[label1])\n",
        "        x2 = x_train[idx2]\n",
        "        pairs_test += [[img, x2]]\n",
        "        labels_test += [1]\n",
        "        # add a non-matching example\n",
        "        label2 = random.randint(0, num_classes - 1)\n",
        "        while label2 == label1:\n",
        "            label2 = random.randint(0, num_classes - 1)\n",
        "        idx2 = random.choice(digit_indices[label2])\n",
        "        x2 = x[idx2]\n",
        "        pairs_test += [[img, x2]]\n",
        "        labels_test += [0]\n",
        "        d = d + 1\n",
        "        if d == 10:\n",
        "            break\n",
        "    return np.array(pairs_test), np.array(labels_test).astype(\"float32\")\n",
        "\n",
        "# pairs_test, labels_test = Create_Pairs_For_Predict(1, x_train, y_train)\n",
        "# x_test_1 = pairs_test[:, 0]  # x_test_1.shape = (20000, 28, 28)\n",
        "# x_test_2 = pairs_test[:, 1]\n",
        "# Predict(x_test_1, x_test_2)\n",
        "#\n",
        "# #visualize(pairs_test,labels_test,to_show=12, num_col=3)\n",
        "#\n",
        "# # predictions = siamese.predict([x_test_1, x_test_2])\n",
        "# # visualize(pairs_test, labels_test, to_show=15, predictions=predictions, test=True)\n",
        "#\n",
        "# num_classes=10\n",
        "# x = x_train[1]\n",
        "# num_classes = 10\n",
        "# digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
        "# pairs_test=[]\n",
        "# labels_test=[]\n",
        "# d=0\n",
        "# num_classes=10\n",
        "# for idx1 in range(len(x_train)):\n",
        "#         # add a matching example\n",
        "#         x1 = x\n",
        "#         label1 = y_train[1]\n",
        "#         idx2 = random.choice(digit_indices[label1])\n",
        "#         x2 = x_train[idx2]\n",
        "#         pairs_test += [[x, x2]]\n",
        "#         labels_test += [1]\n",
        "#         # add a non-matching example\n",
        "#         label2 = random.randint(0, num_classes - 1)\n",
        "#         while label2 == label1:\n",
        "#             label2 = random.randint(0, num_classes - 1)\n",
        "#         idx2 = random.choice(digit_indices[label2])\n",
        "#         x2 = x_train[idx2]\n",
        "#         pairs_test += [[x, x2]]\n",
        "#         labels_test += [0]\n",
        "#         d = d+1\n",
        "#         if d == 10:\n",
        "#           break\n",
        "#\n",
        "# visualize(pairs_test,labels_test,to_show=10, num_col=3)"
      ],
      "metadata": {
        "id": "pqaJdfeiwFnx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}