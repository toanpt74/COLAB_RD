{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/AutoEncode%20For%20Image%20Noise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, BatchNormalization, ReLU, Flatten, Dense, Reshape, Conv2DTranspose\n",
        "\n",
        "def preprocess(array):\n",
        "    \"\"\"\n",
        "    Normalizes the supplied array and reshapes it into the appropriate format.\n",
        "    \"\"\"\n",
        "    array = array.astype(\"float32\") / 255.0\n",
        "    array = np.reshape(array, (len(array), 28, 28, 1))\n",
        "    return array\n",
        "\n",
        "def noise(array):\n",
        "    \"\"\"\n",
        "    Adds random noise to each image in the supplied array.\n",
        "    \"\"\"\n",
        "    noise_factor = 0.4\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "def display(array1, array2):\n",
        "    \"\"\"\n",
        "    Displays ten random images from each one of the supplied arrays.\n",
        "    \"\"\"\n",
        "    n = 10\n",
        "    indices = np.random.randint(len(array1), size=n)\n",
        "    images1 = array1[indices, :]\n",
        "    images2 = array2[indices, :]\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(image1.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(image2.reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "(train_data, _), (test_data, _) = mnist.load_data()\n",
        "# Normalize and reshape the data\n",
        "train_data = preprocess(train_data)\n",
        "test_data = preprocess(test_data)\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(train_data)\n",
        "noisy_test_data = noise(test_data)\n",
        "# Display the train data and a version of it with added noise\n",
        "#display(train_data, noisy_train_data)\n",
        "\n",
        "\n",
        "\n",
        "def encoder(encoder_input):\n",
        "    #Block 1\n",
        "    x = Conv2D(32, kernel_size=3, strides=1, padding='same')(encoder_input)\n",
        "    x= BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    #Block 2\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x= ReLU()(x)\n",
        "    #Block 3\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    #Block 4\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    y = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    #Final Block\n",
        "    flatten = layers.Flatten()(x)\n",
        "    bottleneck = Dense(16)(flatten)\n",
        "    return bottleneck, y.shape\n",
        "def decoder(x, conv_shape):\n",
        "    units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "    x = Dense(units)(x)\n",
        "    x =  layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "    #Block 1\n",
        "    x = Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x=ReLU()(x)\n",
        "    #Block 2\n",
        "    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x=ReLU()(x)\n",
        "    #Block 3\n",
        "    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n",
        "    x=BatchNormalization()(x)\n",
        "    x= ReLU()(x)\n",
        "    #Block 4\n",
        "    x = Conv2DTranspose(32, kernel_size=3, strides=1, padding='same')(x)\n",
        "    x= BatchNormalization()(x)\n",
        "    x= ReLU()(x)\n",
        "    decoder_outputs = Conv2DTranspose(1, 3, 1, padding='same', activation='sigmoid')(x)\n",
        "    return  decoder_outputs\n",
        "\n",
        "\n",
        "input = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "endcoder_output, conv_shape = encoder(input)\n",
        "decoder_outputs = decoder(endcoder_output, conv_shape)\n",
        "model = Model(input,[decoder_outputs])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model.summary()\n",
        "\n",
        "model.fit(\n",
        "    x=noisy_train_data,\n",
        "    y=train_data,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(noisy_test_data, test_data),\n",
        ")\n",
        "predictions = model.predict(noisy_test_data)\n",
        "display(noisy_test_data, predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S2uhKJkZOHsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}