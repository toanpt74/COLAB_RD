{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toanpt74/COLAB_RD/blob/main/Fine_Tuning_NSQL350.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from builtins import print\n",
        "from datetime import datetime\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    prepare_model_for_int8_training,\n",
        "    set_peft_model_state_dict,\n",
        "    PeftModel,\n",
        "    PeftConfig,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from sympy import principal_branch\n",
        "from torch.distributed.autograd import context\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq, pipeline\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, Dataset\n",
        "import json\n",
        "import re\n",
        "\n",
        "os.environ[\"WANDB_MODE\"] =\"offline\"\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "model_final =\"model/nsql-final\"\n",
        "device= \"cuda:0\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_final, torch_dtype=torch.float16, load_in_8bit=False,\n",
        "                                             device_map=device,\n",
        "                                             trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_final)\n",
        "\n",
        "def generateQuery(user_question, user_context, m_new_tokens):\n",
        "    eval_prompt = f\"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
        "You must output the SQL query that answers the question.\n",
        "### Input:\n",
        "{user_question}\n",
        "\n",
        "### Context:\n",
        "{user_context}\n",
        "### Response:\n",
        "\n",
        "\"\"\".strip()\n",
        "    model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    model.eval()\n",
        "    text = tokenizer.decode(model.generate(**model_input, max_new_tokens=m_new_tokens)[0], skip_special_tokens=True)\n",
        "    l = len(text)\n",
        "    p_start = text.find('### Response:')\n",
        "    p_start = p_start + len('### Response:')\n",
        "    strOutput = \"\"\n",
        "    for i in range(p_start + 1, l):\n",
        "        code = ord(text[i])\n",
        "        if code == 10:\n",
        "            p = i\n",
        "            break\n",
        "    strOutput= text[p_start:p]\n",
        "    return strOutput, text\n",
        "\n",
        "user_question=\"What is the production today of the Assy V3 phase?\"\n",
        "user_context=\"CREATE TABLE tblMovingV3(MOVV3_ID uniqueidentifier,CURRENTSITE varchar,ACTIVITY nvarchar,EVENDATE nvarchar,EQPID nvarchar,STEPID nvarchar, PRODUCTID nvarchar,MOVING numeric, V3_WEEK int, V3_MONTH int,V3_YEAR int,V3_DAY int); CREATE TABLE tblEQPList(EQPL_ID uniqueidentifier,MODULE nvarchar,STEPID nvarchar,PROCESS nvarchar,SUB_PROCESS nvarchar, VENDOR nvarchar,EQP_TYPE nvarchar)\"\n",
        "\n",
        "text1, text2 = generateQuery(user_question = user_question, user_context = user_context,  m_new_tokens=1000)\n",
        "print(text1)\n",
        "print('-------------------------------------------------')\n",
        "print(text2)\n",
        "\n"
      ],
      "metadata": {
        "id": "S2uhKJkZOHsW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}